""" Benchmarking the OptiFit algorithm using an external reference database """
import itertools
import shutil

wildcard_constraints:
    seed='\d+',
    region='bact_v4'


subworkflow prep_db:
    workdir:
        "../0_prep_db/"
    configfile:
        f"../../{config['configpath']}"
subworkflow prep_samples:
    workdir:
        "../1_prep_samples/"
    configfile:
        f"../../{config['configpath']}"

configfile: '../../config/config.yaml'

datasets = config['datasets']
refs = config['references']
regions = ['bact_v4']
methods = config['methods']
printrefs = config['printrefs']
seeds = range(1, config['seeds']+1)


rule full_join_optifit_dbs:
    input:
        fcns='../../code/R/functions.R',
        R='../../code/R/full_join_tsvs.R',
        tsv=expand("results/{subdir}/{fn}.tsv",
                    subdir = datasets,
                    fn = ['sensspec', 'benchmarks', 'fraction_reads_mapped']) + [prep_samples('results/dataset_sizes.tsv')]
    output:
        tsv='results/optifit_dbs_results.tsv'
    log:
        'log/full_join.txt'
    script:
        '../../code/R/full_join_tsvs.R'

rule copy_preclust_inputs:  # because filter.seqs doesn't like hyphens in filepaths
    input:
        filter=prep_samples("data/{dataset}/processed/{dataset}.filter"),
        fasta=prep_samples("data/{dataset}/processed/{dataset}.fasta"),
        count=prep_samples("data/{dataset}/processed/{dataset}.count_table"),
        fasta_db=prep_db("data/{ref}/{ref}.{region}.fasta"),
        tax=prep_db("data/{ref}/{ref}.bacteria.tax")
    output:
        filter="data/{dataset}_{ref}_{region}/inputs/{dataset}.filter",
        fasta="data/{dataset}_{ref}_{region}/inputs/{dataset}.fasta",
        count="data/{dataset}_{ref}_{region}/inputs/{dataset}.count_table",
        fasta_db="data/{dataset}_{ref}_{region}/inputs/{ref}.{region}.fasta",
        tax="data/{dataset}_{ref}_{region}/inputs/{ref}.bacteria.tax"
    params:
        outdir="data/{dataset}_{ref}_{region}/inputs/"
    shell:
        """
        cp {input.filter} {output.filter}
        cp {input.fasta} {output.fasta}
        cp {input.count} {output.count}
        cp {input.fasta_db} {output.fasta_db}
        cp {input.tax} {output.tax}
        """

rule preclust_db:
    input:
        fasta_db=rules.copy_preclust_inputs.output.fasta_db,
        fasta_sample=rules.copy_preclust_inputs.output.fasta,
        tax=rules.copy_preclust_inputs.output.tax,
        hard_filter=rules.copy_preclust_inputs.output.filter
    output:
        fasta="data/{dataset}_{ref}_{region}/preclust_db/{ref}.{region}.filter.unique.precluster.fasta",
        count="data/{dataset}_{ref}_{region}/preclust_db/{ref}.{region}.filter.unique.precluster.pick.count_table",
        tax="data/{dataset}_{ref}_{region}/preclust_db/{ref}.{region}.pick.tax",
        dist="data/{dataset}_{ref}_{region}/preclust_db/{ref}.{region}.filter.unique.precluster.dist"
    params:
        tax="data/{dataset}_{ref}_{region}/preclust_db/{ref}.bacteria.pick.tax",
        outdir="data/{dataset}_{ref}_{region}/preclust_db/"
    resources:
        procs=8,
        walltime_hrs=48
    log:
        "log/{dataset}_{ref}_{region}/preclust_db.log"
    benchmark:
        "benchmarks/{dataset}_{ref}_{region}/preclust_db.txt"
    shell:
        """
        mothur '#set.logfile(name={log}); set.dir(output={params.outdir});

        filter.seqs(fasta={input.fasta_db}, hard={input.hard_filter});
        unique.seqs(fasta=current, format=count);
        pre.cluster(fasta=current, count=current, diffs=2, processors={resources.procs});
        dist.seqs(fasta=current, cutoff=0.03, processors={resources.procs});

        list.seqs(fasta=current);
        get.seqs(accnos=current, taxonomy={input.tax});
        get.seqs(accnos=current, count=current);
        summary.seqs(fasta=current, count=current);
        rename.file(input={params.tax}, new={output.tax}) '
        """

rule cluster_db:
    input:
        dist=rules.preclust_db.output.dist,
        count=rules.preclust_db.output.count
    output:
        list="results/{dataset}_{ref}_{region}/cluster_db/seed_{seed}/{ref}.{region}.filter.unique.precluster.opti_mcc.list",
        steps="results/{dataset}_{ref}_{region}/cluster_db/seed_{seed}/{ref}.{region}.filter.unique.precluster.opti_mcc.steps",
        sensspec="results/{dataset}_{ref}_{region}/cluster_db/seed_{seed}/{ref}.{region}.filter.unique.precluster.opti_mcc.sensspec"
    params:
        outdir="results/{dataset}_{ref}_{region}/cluster_db/seed_{seed}/"
    log:
        "log/{dataset}_{ref}_{region}/cluster_db.seed_{seed}.log"
    benchmark:
        "benchmarks/{dataset}_{ref}_{region}/cluster_db.seed_{seed}.txt"
    resources:
        procs=8
    shell:
        """
        mothur '#set.logfile(name={log}); set.dir(output={params.outdir});
        set.seed(seed={wildcards.seed});
        set.current(processors={resources.procs});
        cluster(column={input.dist}, count={input.count}, cutoff=0.03) '
        """


rule pick_best_cluster_seed2:
    input:
        sensspec=expand("results/{{dataset}}_{{ref}}_{{region}}/cluster_db/seed_{seed}/{{ref}}.{{region}}.filter.unique.precluster.opti_mcc.sensspec",
            seed=seeds),
        list=expand("results/{{dataset}}_{{ref}}_{{region}}/cluster_db/seed_{seed}/{{ref}}.{{region}}.filter.unique.precluster.opti_mcc.list",
            seed=seeds),
        code='../../code/R/pick_best_cluster_seed.R',
        fcns='../../code/R/functions.R'
    output:
        list="results/{dataset}_{ref}_{region}/cluster_db/best_seed.opti_mcc.list"
    script:
        '../../code/R/pick_best_cluster_seed.R'

rule mutate_ref_count:
    input:
        count=rules.preclust_db.output.count,
        code="../../code/R/mutate_ref_count.R"
    output:
        count="data/{dataset}_{ref}_{region}/preclust_db/{ref}.{region}.filter.unique.precluster.pick.mod.count_table"
    benchmark:
        "benchmarks/{dataset}_{ref}_{region}/mutate_ref_count.txt"
    script:
        "../../code/R/mutate_ref_count.R"

rule combine_seqs:
    input:
        fasta_sample=rules.copy_preclust_inputs.output.fasta,
        fasta_db=rules.preclust_db.output.fasta,
        count_sample=rules.copy_preclust_inputs.output.count,
        count_db=rules.mutate_ref_count.output.count
    output:
        fasta_all="data/{dataset}_{ref}_{region}/combined_seqs/{dataset}_{ref}.{region}.all.fasta",
        count_all="data/{dataset}_{ref}_{region}/combined_seqs/{dataset}_{ref}.{region}.all.count_table",
        accnos_refs="data/{dataset}_{ref}_{region}/combined_seqs/{ref}.{region}.filter.unique.precluster.accnos"
    params:
        outdir="data/{dataset}_{ref}_{region}/combined_seqs/"
    log:
        "log/{dataset}_{ref}_{region}/combine_seqs.log"
    benchmark:
        "benchmarks/{dataset}_{ref}_{region}/combine_seqs.txt"
    shell:
        """
        cat {input.fasta_sample} {input.fasta_db} > {output.fasta_all}
        mothur '#set.logfile(name={log}); set.dir(output={params.outdir});
            list.seqs(fasta={input.fasta_sample});
            list.seqs(fasta={input.fasta_db});
            merge.count(count={input.count_sample}-{input.count_db}, output={output.count_all})
        '
        """

rule calc_dists_combined:
    input:
        fasta=rules.combine_seqs.output.fasta_all
    output:
        column="data/{dataset}_{ref}_{region}/combined_seqs/{dataset}_{ref}.{region}.all.dist"
    params:
        outdir="data/{dataset}_{ref}_{region}/combined_seqs/"
    log:
        "log/{dataset}_{ref}_{region}/calc_dists_combined.log"
    benchmark:
        "benchmarks/{dataset}_{ref}_{region}/calc_dists_combined.txt"
    resources:
        procs=16
    shell:
        """
        mothur '#set.logfile(name={log}); set.dir(output={params.outdir});
            dist.seqs(fasta={input.fasta}, cutoff=0.03, processors={resources.procs}) '
        """

rule fit_to_ref_db:
    input:
        fasta=rules.combine_seqs.output.fasta_all,
        count=rules.combine_seqs.output.count_all,
        column=rules.calc_dists_combined.output.column,
        reflist=rules.pick_best_cluster_seed2.output.list
    output:
        sensspec='results/{dataset}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/{dataset}_{ref}.{region}.all.optifit_mcc.sensspec',
        list='results/{dataset}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/{dataset}_{ref}.{region}.all.optifit_mcc.list',
    params:
        outdir="results/{dataset}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/"
    benchmark:
        "benchmarks/{dataset}_{ref}_{region}/optifit.method_{method}.printref_{printref}.seed_{seed}.txt"
    log:
        "log/{dataset}_{ref}_{region}/optifit.method_{method}.printref_{printref}.seed_{seed}.log"
    resources:
        procs=8
    shell:
        """
        mothur "#set.logfile(name={log}); set.dir(output={params.outdir});
        set.seed(seed={wildcards.seed});
        set.current(processors={resources.procs});
        cluster.fit(reflist={input.reflist}, fasta={input.fasta}, count={input.count}, column={input.column},  printref={wildcards.printref}, method={wildcards.method}) "
        """

rule calc_diversity2:
    input:
        list=rules.fit_to_ref_db.output.list,
        count=rules.copy_preclust_inputs.output.count
    output:
        tsv=temp('results/{dataset}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/{dataset}.pick.optifit_mcc.groups.summary')
    params:
        outdir="results/{dataset}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/"
    log:
        "log/{dataset}_{ref}_{region}/calc_diversity.method_{method}.printref_{printref}.seed_{seed}.log"
    shell:
        """
        mothur "#set.logfile(name={log}); set.dir(output={params.outdir});
        list.seqs(list={input.list});
        get.seqs(count={input.count}, accnos=current);
        make.shared(list={input.list}, count=current, label=0.03);
        summary.single(shared=current, calc=nseqs-sobs-npshannon-invsimpson) "
        """

rule reformat_optifit_results2:  # for plotting
    input:
        sensspec=rules.fit_to_ref_db.output.sensspec,
        bench=rules.fit_to_ref_db.benchmark,
        div=rules.calc_diversity2.output.tsv,
        code="../../code/R/reformat_optifit_results.R",
        fcns='../../code/R/functions.R'
    output:
        sensspec='results/{dataset}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/{dataset}_{ref}.{region}.all.optifit_mcc.mod.sensspec',
        bench='benchmarks/{dataset}_{ref}_{region}/optifit.method_{method}.printref_{printref}.seed_{seed}.mod.txt',
        div='results/{dataset}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/{dataset}.pick.optifit_mcc.groups.mod.summary'
    benchmark:
        "benchmarks/{dataset}_{ref}_{region}/reformat_optifit_results.method_{method}.printref_{printref}.seed_{seed}.txt"
    params:
        dataset="{dataset}",
        ref="{ref}",
        region="{region}",
        seed="{seed}",
        printref='{printref}',
        method='{method}'
    script:
        "../../code/R/reformat_optifit_results.R"

rule fraction_reads_mapped:
    input:
        code="../../code/py/fraction_reads_mapped.py",
        list=rules.fit_to_ref_db.output.list,
        count=rules.copy_preclust_inputs.output.count
    output:
        txt='results/{dataset}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/fraction_reads_mapped.txt'
    wildcard_constraints:
        method='closed'
    script:
        "../../code/py/fraction_reads_mapped.py"

rule rbind_results2:
    input:
        sensspec=expand('results/{{dataset}}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/{{dataset}}_{ref}.{region}.all.optifit_mcc.mod.sensspec',
            ref=refs, region=regions, seed=seeds, method=methods, printref=printrefs),
        bench=expand('benchmarks/{{dataset}}_{ref}_{region}/optifit.method_{method}.printref_{printref}.seed_{seed}.mod.txt',
            ref=refs, region=regions, seed=seeds, method=methods, printref=printrefs),
        div=expand('results/{{dataset}}_{ref}_{region}/optifit/method_{method}/printref_{printref}/seed_{seed}/{{dataset}}.pick.optifit_mcc.groups.mod.summary',
            ref=refs, region=regions, seed=seeds, method=methods, printref=printrefs),
        fcns='../../code/R/functions.R',
        code='../../code/R/rbind_results.R'
    output:
        sensspec="results/{dataset}/sensspec.tsv",
        bench="results/{dataset}/benchmarks.tsv",
        div='results/{dataset}/diversity.tsv'
    benchmark:
        "benchmarks/{dataset}/rbind_results.txt"
    script:
        '../../code/R/rbind_results.R'

rule merge_fraction_mapped2:
    input:
        tsv=expand('results/{{dataset}}_{ref}_{region}/optifit/method_closed/printref_{printref}/seed_{seed}/fraction_reads_mapped.txt',
            ref=refs, region=regions, printref=printrefs, seed=seeds),
        code='../../code/R/rbind_tsv.R',
        fcns='../../code/R/functions.R'
    output:
        tsv='results/{dataset}/fraction_reads_mapped.tsv'
    script:
        '../../code/R/rbind_tsv.R'

def count_seqs(filename):
    with open(filename, 'r') as infile:
        num_seqs = sum(1 for line in infile if line.startswith('>'))
    return num_seqs

rule count_ref_sizes:
    input:
        fasta=expand("data/{dataset}_{ref}_{region}/preclust_db/{ref}.{region}.filter.unique.precluster.fasta", dataset=datasets, ref=refs, region=regions)
    output:
        txt='results/ref_sizes.tsv'
    benchmark:
        'benchmarks/count_ref_sizes.txt'
    run:
        with open(output.txt, 'w') as outfile:
            outfile.write('reference\tregion\tnum_seqs\tdataset_filter\n')
            for filename in input.fasta:
                parameters = filename.split('/')[1].split('_')
                num_seqs = count_seqs(filename)
                dataset = parameters[0]
                ref = parameters[1]
                region = parameters[3]
                outfile.write(f"{ref}\t{region}\t{num_seqs}\t{dataset}\n")
