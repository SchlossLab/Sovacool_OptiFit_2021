"""
Running de novo, open-reference, and closed-reference clustering with vsearch.

vsearch commands adapted from:
- https://github.com/SchlossLab/Schloss_Cluster_PeerJ_2015/blob/master/code/run_vdgc_clust.sh
- https://github.com/qiime2/q2-vsearch/blob/master/q2_vsearch/_cluster_features.py
"""

# config params
configfile: 'config/config.yaml'
datasets = config['datasets']
refs = config['references']
methods = config['methods']

# hard-coded params
regions = ['bact_v4']
perc_identity = 0.97  # to match mothur's 0.3 dissimilarity threshold
min_seq_length = 30 # from Pat's vsearch script
max_accepts = 16
max_rejects = 64
# the default value of wordlength is already 8 but I'm paranoid
word_length = 8

wildcard_constraints:
    region='bact_v4'

subworkflow prep_db:
    workdir:
        "../0_prep_db/"
    configfile:
        config['configpath']
subworkflow prep_samples:
    workdir:
        "../1_prep_samples/"
    configfile:
        config['configpath']

ruleorder: combine_open_lists > uc_to_list

rule aggregate_vsearch_results:
    input:
        tsv=expand('results/{dataset}/{method}/results.{dataset}.tsv',
                    dataset=datasets,
                    method=methods + ['de_novo']),
        fcns='code/R/functions.R',
        R='code/R/rbind_tsv.R'
    output:
        tsv='results/vsearch_results.tsv'
    script:
        'code/R/rbind_tsv.R'

# some mothur commands don't like hyphens in file paths
rule copy_query_files:
    input:
        fna=prep_samples("data/{dataset}/processed/{dataset}.fasta"),
        count_table=prep_samples("data/{dataset}/processed/{dataset}.count_table"),
        dist=prep_samples("results/{dataset}/{dataset}.dist")
    output:
        fna='data/{dataset}/input/{dataset}.fasta',
        count_table='data/{dataset}/input/{dataset}.count_table',
        dist='data/{dataset}/input/{dataset}.dist'
    params:
        outdir='data/{dataset}/input/'
    shell:
        """
        for f in {input}; do
            cp $f {params.outdir}
        done
        """

# vsearch doesn't support dots or hyphens in fasta headers
rule prep_query_seqs:
    input:
        fna=rules.copy_query_files.output.fna,
        count_table=rules.copy_query_files.output.count_table,
        dist=rules.copy_query_files.output.dist,
        py='code/py/remove_hyphens_dist.py'
    output:
        degap=temp("data/{dataset}/{dataset}.tmp.fasta"),
        fna="data/{dataset}/{dataset}.ng.fasta",
        count_table='data/{dataset}/{dataset}.ng.count_table',
        dist='data/{dataset}/{dataset}.ng.dist'
    log:
        'log/{dataset}/remove_gaps_query.log'
    params:
        outdir="data/{dataset}/",
        prefix='{dataset}.tmp'
    shell:
        """
        mothur '#set.logfile(name={log}); set.dir(output={params.outdir});
            deunique.seqs(fasta={input.fna}, count={input.count_table});
            degap.seqs(fasta=current);
            rename.file(fasta=current, prefix={params.prefix}) '
        cat {output.degap} | sed 's/[\.-]/_/g' > {output.fna}
        cat {input.count_table} |  sed 's/[\.-]/_/g' > {output.count_table}
        python {input.py} {input.dist} {output.dist}
        """

rule copy_ref:
    input:
        prep_db("data/gg/gg_13_8_otus/rep_set/97_otus.fasta")
    output:
        fasta='data/ref/gg.fasta'
    shell:
        """
        cp {input} {output}
        """

rule list_ref_seqs:
    input:
        fasta=rules.copy_ref.output.fasta
    output:
        accnos='data/ref/gg.accnos'
    log:
        'log/list_ref_seqs.log'
    params:
        outdir='data/ref/'
    shell:
        """
        mothur '#set.dir(output={params.outdir}); set.logfile(name={log});
            list.seqs(fasta={input.fasta}) '
        """

rule vsearch_sort:
    input:
        fna=rules.prep_query_seqs.output.fna
    output:
        fna="data/{dataset}/{dataset}.ng.sorted.fasta",
        uc="data/{dataset}/{dataset}.ng.sorted.uc"
    shell:
        """
        vsearch \
            --derep_fulllength {input.fna} \
            --sizeout \
            --minseqlength 30 \
            --threads 1 \
            --uc {output.uc} \
            --output {output.fna} \
            --strand both
        """

rule vsearch_de_novo:
    input:
        query=rules.vsearch_sort.output.fna
    output:
        uc='results/{dataset}/de_novo/{dataset}.uc'
    benchmark:
        'benchmarks/{dataset}/vsearch.method_de_novo.{dataset}.txt'
    params:
        perc_identity=perc_identity,
        min_seq_length=min_seq_length,
        max_accepts=max_accepts,
        max_rejects=max_rejects,
        word_length=word_length
    resources:
        procs=8
    shell:
        """
        vsearch --cluster_smallmem {input.query} \
            --usersort \
            --uc {output.uc} \
            --threads {resources.procs} \
            --id {params.perc_identity} \
            --minseqlength {params.min_seq_length} \
            --maxaccepts {params.max_accepts} \
            --maxrejects {params.max_rejects} \
            --wordlength {params.word_length} \
            --strand both \
            --relabel OTU_
        """

rule vsearch_closed_ref:
    input:
        query=rules.vsearch_sort.output.fna,
        ref=rules.copy_ref.output.fasta
    output:
        uc='results/{dataset}/closed/{dataset}.uc',
        unmatched='results/{dataset}/closed/{dataset}.unmatched.fasta'
    benchmark:
        'benchmarks/{dataset}/vsearch.method_closed.{dataset}.txt'
    params:
        perc_identity=perc_identity,
        min_seq_length=min_seq_length,
        max_accepts=max_accepts,
        max_rejects=max_rejects,
        word_length=word_length
    resources:
        procs=8
    shell:
        """
        vsearch --usearch_global {input.query} \
            --db {input.ref} \
            --notmatched {output.unmatched} \
            --uc {output.uc} \
            --threads {resources.procs} \
            --id {params.perc_identity} \
            --minseqlength {params.min_seq_length} \
            --maxaccepts {params.max_accepts} \
            --maxrejects {params.max_rejects} \
            --wordlength {params.word_length} \
            --strand both
        """

rule vsearch_open_ref:
    input:
        query=rules.vsearch_sort.output.fna,
        ref=rules.copy_ref.output.fasta
    output:
        closed='results/{dataset}/open/{dataset}.closed.uc',
        unmatched='results/{dataset}/open/{dataset}.unmatched.fasta',
        denovo='results/{dataset}/open/{dataset}.denovo.uc'
    benchmark:
        'benchmarks/{dataset}/vsearch.method_open.{dataset}.txt'
    params:
        perc_identity=perc_identity,
        min_seq_length=min_seq_length,
        max_accepts=max_accepts,
        max_rejects=max_rejects,
        word_length=word_length
    resources:
        procs=8
    shell:
        """
        vsearch --usearch_global {input.query} \
            --db {input.ref} \
            --notmatched {output.unmatched} \
            --uc {output.closed} \
            --threads {resources.procs} \
            --id {params.perc_identity} \
            --minseqlength {params.min_seq_length} \
            --maxaccepts {params.max_accepts} \
            --maxrejects {params.max_rejects} \
            --wordlength {params.word_length} \
            --strand both
        vsearch --cluster_smallmem {output.unmatched} \
            --usersort \
            --uc {output.denovo} \
            --threads {resources.procs} \
            --id {params.perc_identity} \
            --minseqlength {params.min_seq_length} \
            --maxaccepts {params.max_accepts} \
            --maxrejects {params.max_rejects} \
            --wordlength {params.word_length} \
            --strand both \
            --relabel OTU_
        """

rule uc_to_list:
    input:
        code='code/R/uc_to_list.R',
        sorted=rules.vsearch_sort.output.uc,
        clustered='results/{dataset}/{method}/{dataset_step}.uc'
    output:
        list='results/{dataset}/{method}/{dataset_step}.list'
    shell:
        'Rscript {input.code} {input.sorted} {input.clustered} {output.list}'

rule combine_open_lists:
    input:
        l1='results/{dataset}/open/{dataset}.closed.list',
        l2='results/{dataset}/open/{dataset}.denovo.list',
        py='code/py/combine_open_lists.py'
    output:
        list='results/{dataset}/open/{dataset}.list'
    script:
        'code/py/combine_open_lists.py'

rule sensspec_vsearch:
    input:
        list="results/{dataset}/{method}/{dataset}.list",
        count_table=rules.prep_query_seqs.output.count_table,
        dist=rules.prep_query_seqs.output.dist
    output:
        tsv='results/{dataset}/{method}/{dataset}.sensspec'
    params:
        outdir='results/{dataset}/{method}/'
    log:
        'log/{dataset}/sensspec.method_{method}.{dataset}.txt'
    shell:
        """
        mothur '#set.logfile(name={log}); set.dir(output={params.outdir});
            sens.spec(list={input.list}, count={input.count_table}, column={input.dist}) '
        """

rule calc_diversity4:
    input:
        list="results/{dataset}/{method}/{dataset}.list",
        count_table=rules.prep_query_seqs.output.count_table,
    output:
        list_accnos="results/{dataset}/{method}/{dataset}.accnos",
        tsv='results/{dataset}/{method}/{dataset}.groups.summary'
    params:
        outdir="results/{dataset}/{method}/"
    log:
        "log/{dataset}/calc_diversity.{dataset}.method_{method}.txt"
    shell:
        """
        mothur "#set.logfile(name={log}); set.dir(output={params.outdir});
        list.seqs(list={input.list});
        get.seqs(count={input.count_table}, accnos=current);
        make.shared(list={input.list}, count=current, label=0.03);
        summary.single(shared=current, calc=nseqs-sobs-shannon-invsimpson) "
        """

rule fraction_reads_mapped4:
    input:
        code="code/py/fraction_mapped_vsearch.py",
        mapped=rules.calc_diversity4.output.list_accnos,
        query=rules.prep_query_seqs.output.count_table,
        ref=rules.list_ref_seqs.output.accnos
    output:
        txt='results/{dataset}/{method}/fraction-mapped_{dataset}.txt'
    script:
        "code/py/fraction_mapped_vsearch.py"

rule reformat_vsearch_results:
    input:
        R="code/R/reformat_vsearch_results.R",
        fcns='code/R/functions.R',
        bench='benchmarks/{dataset}/vsearch.method_{method}.{dataset}.txt',
        sensspec=rules.sensspec_vsearch.output.tsv,
        div=rules.calc_diversity4.output.tsv,
        map=rules.fraction_reads_mapped4.output.txt
    output:
        tsv='results/{dataset}/{method}/results.{dataset}.tsv'
    script:
        "code/R/reformat_vsearch_results.R"

