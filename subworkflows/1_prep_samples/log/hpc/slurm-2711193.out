Building DAG of jobs...
Files requested from subworkflow:
    
Subworkflow prep_db: Nothing to be done.
Executing main workflow.
Checking status of 0 jobs.
Using shell: /usr/bin/bash
Provided cluster nodes: 4999
Job counts:
	count	jobs
	2	download
	2	names_file
	4
Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (2):
	download
	download
Selected jobs (2):
	download
	download
Resources after job selection: {'_cores': 9223372036854775805, '_nodes': 4997}

[Thu Dec 12 21:07:18 2019]
checkpoint download:
    input: data/soil/SRR_Acc_List.txt, code/download.sh
    output: data/soil/raw
    jobid: 2
    benchmark: benchmarks/soil/download.txt
    wildcards: dataset=soil
Downstream jobs will be updated after completion.

Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "download", "local": false, "input": ["data/soil/SRR_Acc_List.txt", "code/download.sh"], "output": ["data/soil/raw"], "wildcards": {"dataset": "soil"}, "params": {}, "log": [], "threads": 1, "resources": {}, "jobid": 2, "cluster": {"account_pbs": "pschloss_fluxod", "account_slurm": "pschloss", "queue": "fluxod", "qos": "flux", "partition": "standard", "jobname": "download.dataset=soil", "nodes": 1, "procs": 1, "pmem": "4GB", "walltime": "96:00:00", "email": "sovacool@umich.edu", "mailon": "a", "mail_type": "FAIL", "jobout": "oe", "outdir": "log/hpc/", "outfile": "log/hpc/slurm-%j.out"}}
cd /nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples && \
/home/sovacool/bin/miniconda3/envs/optifit/bin/python3.7 \
-m snakemake data/soil/raw --snakefile /nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples/Snakefile \
--force -j --keep-target-files --keep-remote \
--wait-for-files /nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples/.snakemake/tmp.b95cu6kc data/soil/SRR_Acc_List.txt code/download.sh --latency-wait 30 \
 --attempt 1 --force-use-threads \
--wrapper-prefix https://bitbucket.org/snakemake/snakemake-wrappers/raw/ \
   --allowed-rules download --nocolor --notemp --no-hooks --nolock \
--mode 2  && touch "/nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples/.snakemake/tmp.b95cu6kc/2.jobfinished" || (touch "/nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples/.snakemake/tmp.b95cu6kc/2.jobfailed"; exit 1)

Submitted job 2 with external jobid 'Submitted batch job 2711195'.

[Thu Dec 12 21:07:20 2019]
checkpoint download:
    input: data/human/SRR_Acc_List.txt, code/download.sh
    output: data/human/raw
    jobid: 3
    benchmark: benchmarks/human/download.txt
    wildcards: dataset=human
Downstream jobs will be updated after completion.

Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "download", "local": false, "input": ["data/human/SRR_Acc_List.txt", "code/download.sh"], "output": ["data/human/raw"], "wildcards": {"dataset": "human"}, "params": {}, "log": [], "threads": 1, "resources": {}, "jobid": 3, "cluster": {"account_pbs": "pschloss_fluxod", "account_slurm": "pschloss", "queue": "fluxod", "qos": "flux", "partition": "standard", "jobname": "download.dataset=human", "nodes": 1, "procs": 1, "pmem": "4GB", "walltime": "96:00:00", "email": "sovacool@umich.edu", "mailon": "a", "mail_type": "FAIL", "jobout": "oe", "outdir": "log/hpc/", "outfile": "log/hpc/slurm-%j.out"}}
cd /nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples && \
/home/sovacool/bin/miniconda3/envs/optifit/bin/python3.7 \
-m snakemake data/human/raw --snakefile /nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples/Snakefile \
--force -j --keep-target-files --keep-remote \
--wait-for-files /nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples/.snakemake/tmp.b95cu6kc data/human/SRR_Acc_List.txt code/download.sh --latency-wait 30 \
 --attempt 1 --force-use-threads \
--wrapper-prefix https://bitbucket.org/snakemake/snakemake-wrappers/raw/ \
   --allowed-rules download --nocolor --notemp --no-hooks --nolock \
--mode 2  && touch "/nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples/.snakemake/tmp.b95cu6kc/3.jobfinished" || (touch "/nfs/turbo/schloss-lab/sovacool/optiFit/subworkflows/1_prep_samples/.snakemake/tmp.b95cu6kc/3.jobfailed"; exit 1)

Submitted job 3 with external jobid 'Submitted batch job 2711197'.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
Checking status of 2 jobs.
