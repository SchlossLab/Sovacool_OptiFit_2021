import os

configfile: 'config/config.yaml'

datasets = config['datasets']
seeds = range(1, config['seeds']+1)

subworkflow prep_db:
    workdir:
        "../0_prep_db/"
    configfile:
        config['configpath']

wildcard_constraints:
    seed='\d+'

def get_sra_list(dataset):
    with open(f"data/{dataset}/SRR_Acc_List.txt", 'r') as file:
        sra = [line.strip() for line in file]
    return sra

sra_list = {dataset: get_sra_list(dataset) for dataset in ['human', 'marine', 'soil']}

with open("data/mouse/SRR_Acc_List.txt", 'r') as file:
    mouse_filenames = [f"data/mouse/raw/{line.strip()}" for line in file]

rule rbind_opticlust:
    input:
        fcns='code/R/functions.R',
        R='code/R/rbind_tsv.R',
        tsv=expand("results/{dataset}/cluster/seed_{seed}/results.tsv",
                    dataset = datasets,
                    seed = seeds),
        xtra='results/dataset_sizes.tsv' # because this is the target rule
    output:
        tsv='results/opticlust_results.tsv'
    log:
        'log/full_join.txt'
    script:
        '../../code/R/rbind_tsv.R'

rule fastq_targets:
    input:
        [f"data/{dataset}/raw/{sra}_{i}.fastq.gz" for dataset in ['human', 'marine', 'soil'] for sra in sra_list[dataset] for i in (1,2)]

rule download_most:
    input:
        list="data/{dataset}/SRR_Acc_List.txt",
        sh="code/bash/download.sh"
    output:
        fastq=expand("data/{{dataset}}/raw/{{SRA}}_{i}.fastq.gz", i=(1,2))
    params:
        sra="{SRA}",
        outdir="data/{dataset}/raw"
    wildcard_constraints:
        dataset="human|marine|soil"
    shell:
        """
        bash {input.sh} {params.sra} {params.outdir}
        """

rule download_mouse:
    input:
        list="data/mouse/SRR_Acc_List.txt",
        sh="code/bash/download.sh"
    output:
        files=mouse_filenames
    params:
        tar="data/mouse/StabilityNoMetaG.tar",
        url="http://www.mothur.org/MiSeqDevelopmentData/StabilityNoMetaG.tar"
    shell:
        """
        wget -N -P data/mouse/ {params.url}
        tar -xvf {params.tar} -C data/mouse/raw/
        rm {params.tar}
        """


rule names_file_human:
    input:
        R="code/R/human.R",
        files=expand("data/human/raw/{SRA}_{i}.fastq.gz", SRA=sra_list["human"], i=(1,2))
    output:
        file="data/human/human.files"
    shell:
        "Rscript {input.R}"

rule names_file_marine:
    input:
        R="code/R/marine.R",
        files=expand("data/marine/raw/{SRA}_{i}.fastq.gz", SRA=sra_list["marine"], i=(1,2))
    output:
        file="data/marine/marine.files"
    shell:
        "Rscript {input.R}"

rule names_file_mouse:
    input:
        files=rules.download_mouse.output.files,
        script="code/py/mouse.py"
    output:
        file="data/mouse/mouse.files"
    params:
        dir="data/mouse/raw"
    shell:
        "python {input.script}"

rule names_file_soil:
    input:
        R="code/R/soil.R",
        files=expand("data/soil/raw/{SRA}_{i}.fastq.gz", SRA=sra_list["soil"], i=(1,2))
    output:
        file="data/soil/soil.files"
    shell:
        "Rscript {input.R}"

rule copy_refs:
    input:
        align_db=prep_db("data/silva/silva.bact_v4.fasta"),
        rdp_fasta=prep_db("data/rdp/rdp.fasta"),
        rdp_tax=prep_db("data/rdp/rdp.tax")
    output:
        align_db='data/refs/silva.bact_v4.fasta',
        rdp_fasta='data/refs/rdp.fasta',
        rdp_tax='data/refs/rdp.tax'
    shell:
        """
        cp {input.align_db} {output.align_db}
        cp {input.rdp_fasta} {output.rdp_fasta}
        cp {input.rdp_tax} {output.rdp_tax}
        """

rule preprocess:
    input:
        file="data/{dataset}/{dataset}.files",
        align_db=rules.copy_refs.output.align_db,
        rdp_fasta=rules.copy_refs.output.rdp_fasta,
        rdp_tax=rules.copy_refs.output.rdp_tax
    output:
        filter="data/{dataset}/processed/{dataset}.filter",
        count=temp("data/{dataset}/processed/{dataset}.temp.count_table"),
        tax="data/{dataset}/processed/{dataset}.tax",
        fasta="data/{dataset}/processed/{dataset}.fasta"
    params:
        workdir="data/{dataset}/temp/",
        filter="data/{dataset}/temp/{dataset}.filter",
        tax="data/{dataset}/temp/{dataset}.trim.contigs.good.unique.good.filter.unique.precluster.pick.rdp.wang.pick.taxonomy",
        fasta="data/{dataset}/temp/{dataset}.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta",
        count="data/{dataset}/temp/{dataset}.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.count_table",
        trim_contigs='data/{dataset}/temp/{dataset}.trim.contigs.fasta',
        contigs_groups='data/{dataset}/temp/{dataset}.contigs.groups'
    log:
        "log/{dataset}/preprocess.log"
    resources:
        procs=12,
        pmem=12
    shell:
        """
        mothur '#set.logfile(name={log});
            set.dir(input=data/{wildcards.dataset}/raw, output={params.workdir});
            make.contigs(inputdir=data/{wildcards.dataset}/raw, file={input.file}, processors={resources.procs});
            set.dir(input=data/{wildcards.dataset}/raw, output={params.workdir});
            screen.seqs(fasta={params.trim_contigs}, group={params.contigs_groups}, maxambig=0, maxlength=275, maxhomop=8);
            unique.seqs();
            count.seqs(name=current, group=current);
            align.seqs(fasta=current, reference={input.align_db}, processors={resources.procs});
            screen.seqs(fasta=current, count=current, start=1968, end=11550);
            filter.seqs(fasta=current, vertical=T, trump=.);
            unique.seqs(fasta=current, count=current);
            pre.cluster(fasta=current, count=current, diffs=2);
            chimera.uchime(fasta=current, count=current, dereplicate=T);
            remove.seqs(fasta=current, accnos=current);
            classify.seqs(fasta=current, count=current, reference={input.rdp_fasta}, taxonomy={input.rdp_tax}, cutoff=80);
            remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota); '
        mv {params.filter} {output.filter}
        mv {params.tax} {output.tax}
        mv {params.fasta} {output.fasta}
        mv {params.count} {output.count}
        rm -rf data/{wildcards.dataset}/temp/
        """

rule mutate_count1:
    input:
        count=rules.preprocess.output.count,
        code="code/R/mutate_ref_count.R"
    output:
        count='data/{dataset}/processed/{dataset}.count_table'
    script:
        "code/R/mutate_ref_count.R"

def count_seqs(filename):
    with open(filename, 'r') as infile:
        num_seqs = sum(1 for line in infile if line.startswith('>'))
    return num_seqs

rule count_dataset_sizes:
    input:
        fasta=expand('data/{dataset}/processed/{dataset}.fasta', dataset=datasets)
    output:
        txt='results/dataset_sizes.tsv'
    run:
        with open(output.txt, 'w') as outfile:
            outfile.write('dataset\tnum_seqs\n')
            for filename in input.fasta:
                num_seqs = count_seqs(filename)
                parameters = filename.split('/')[1].split('_')
                dataset = parameters[0]
                outfile.write(f"{dataset}\t{num_seqs}\n")

rule calc_dists_dataset:
    input:
        fasta=rules.preprocess.output.fasta
    output:
        column="results/{dataset}/{dataset}.dist"
    params:
        outdir="results/{dataset}/"
    log:
        "log/{dataset}/calc_dists.log"
    resources:
        procs=16
    shell:
        """
        mothur '#set.logfile(name={log}); set.dir(output={params.outdir});
            dist.seqs(fasta={input.fasta}, cutoff=0.03, processors={resources.procs}) '
        """

rule cluster_dataset:
    input:
        dist=rules.calc_dists_dataset.output.column,
        count=rules.mutate_count1.output.count
    output:
        list="results/{dataset}/cluster/seed_{seed}/{dataset}.opti_mcc.list",
        sensspec='results/{dataset}/cluster/seed_{seed}/{dataset}.opti_mcc.sensspec'
    params:
        outdir="results/{dataset}/cluster/seed_{seed}/"
    log:
        "log/{dataset}/cluster.seed_{seed}.log"
    benchmark:
        "benchmarks/{dataset}/cluster.seed_{seed}.txt"
    resources:
        procs=8
    shell:
        """
        mothur '#set.logfile(name={log}); set.dir(output={params.outdir});
        set.seed(seed={wildcards.seed});
        set.current(processors={resources.procs});
        cluster(column={input.dist}, count={input.count}, cutoff=0.03) '
        """

rule calc_diversity1:
    input:
        list=rules.cluster_dataset.output.list,
        count=rules.mutate_count1.output.count
    output:
        tsv="results/{dataset}/cluster/seed_{seed}/{dataset}.opti_mcc.groups.summary"
    params:
        outdir="results/{dataset}/cluster/seed_{seed}/"
    log:
        "log/{dataset}/calc_diversity.seed_{seed}.txt"
    shell:
        """
        mothur "#set.logfile(name={log}); set.dir(output={params.outdir});
        list.seqs(list={input.list});
        get.seqs(count={input.count}, accnos=current);
        make.shared(list={input.list}, count=current, label=0.03);
        summary.single(shared=current, calc=nseqs-sobs-npshannon-invsimpson) "
        """

rule cbind_opticlust_seed:
    input:
        tsv=[rules.cluster_dataset.output.sensspec,
            rules.cluster_dataset.benchmark,
            rules.calc_diversity1.output.tsv],
        code='code/R/cbind_opticlust_seed.R',
        fcns='code/R/functions.R'
    output:
        tsv="results/{dataset}/cluster/seed_{seed}/results.tsv"
    script:
        'code/R/cbind_opticlust_seed.R'

