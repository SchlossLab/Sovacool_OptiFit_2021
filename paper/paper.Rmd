---
title: "OptiFit: a fast method for fitting amplicon sequences to existing OTUs"
date: '`r Sys.Date()`'
authors:
  - name: "Kelly L. Sovacool"
    url: https://github.com/kelly-sovacool
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
    orcid_id: 0000-0003-3283-829X
  - name: "Sarah L. Westcott"
    url: https://github.com/mothur-westcott
    affiliation: Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
  - name: "M. Brodie Mumphrey"
    url: https://github.com/MBMumphrey
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
  - name: "Gabrielle A. Dotson"
    url: https://github.com/dotsonga
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
  - name: "Patrick D. Schloss"
    url: https://github.com/pschloss
    affiliation: Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
bibliography: references.bib
output:
  distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
  pdf_document:
    keep_tex: false
    includes:
      in_header: preamble.tex
      before_body: head.tex
      after_body: tail.tex
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs", output_format = "all") })
csl: msystems.csl
fontsize: 12pt
geometry: margin=1.0in
repository_url: https://github.com/SchlossLab/OptiFitAnalysis
creative_commons: CC BY-SA
twitter:
  creator: "@kelly_sovacool"
  site: "@PatSchloss"
---

```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE}
mothuR::set_knitr_opts()
```

```{r deps, message = FALSE}
library(here)
library(mothuR)
library(tidyverse)
load(here('results', 'stats.RData'))
```

- **"AND, BUT, THEREFORE" structure. start paragraph with question, end with why we should care. transitions to move the story along.**
- From Pat: "briefly looking through the Discussion and Intro, one point that we may have forgotten is that a benefit of our approach is that it is much easier to customize to a specific region. The greengenes reference OTUs are based on full length sequences. This causes problems when considering shorter (e.g. V4) sequences since reference OTUs may be more similar  than the full length and even identical to each other in the subregion. Because we can easily spin up a subregion specific set of reference OTUs from a public database or the reference fraction this isn't a problem. This is described in one of my earlier papers looking at open/closed reference clustering and was part of the reason that the order of the database was important."

## Abstract

Assigning amplicon sequences to Operational Taxonomic Units (OTUs) is an
important step in characterizing the composition of microbial communities across
large datasets.
OptiClust, a _de novo_ OTU clustering method in the mothur program, has been
shown to produce higher quality OTU assignments than other methods and at
comparable or faster speeds [@westcott_opticlust_2017;
@schloss_introducing_2009].
A notable difference between _de novo_ clustering and database-dependent methods
is that OTU assignments clustered with _de novo_ methods are not stable when new
sequences are added to a dataset [@westcott_novo_2015].
However, in some cases one may wish to incorporate new samples into a previously
clustered dataset without performing clustering again on all sequences, such as
when deploying a machine learning model where OTUs are features
[@topcuoglu_effective_2019].
To provide an efficient and robust method to fit amplicon sequence data to
existing OTUs, we developed the OptiFit algorithm as a new component of the
mothur program.

**TODO: summarize results & conclusion**

### Importance

**TODO**

\newpage

## Introduction

Amplicon sequencing has become a mainstay of microbial ecology and
host-associated microbiome research.
Researchers can affordably generate millions of sequences to characterize the
composition of hundreds of samples from culture-independent microbial
communities. In a typical analysis pipeline,
16S rRNA gene sequences are assigned to Operational Taxonomic Units (OTUs) to
facilitate comparison of taxonomic composition between communities.
A distance threshold of 3% (or sequence similarity of 97%) is commonly used to
cluster sequences into OTUs based on either a reference database or pairwise
comparisons of the sequences within the dataset.
The method chosen for clustering affects the quality of OTU assignments and thus
may impact downstream analyses of community composition
[@westcott_opticlust_2017; @schloss_application_2016;
@westcott_novo_2015].

There are three main categories of OTU clustering algorithms: closed reference,
open reference, and _de novo_ clustering. 
Closed reference methods assign sequences to a set of pre-made OTUs generated
from reference sequences.
If a query sequence is not within the distance threshold to any of the reference
sequences, it is discarded.
While reference-based clustering is generally fast, it is limited by the
diversity of the reference database.
Rare or novel sequences in the sample will be lost if they are not represented
by a similar sequence in the database.
_De novo_ methods cluster sequences based on their distance to each other,
without the use of an external reference.
_De novo_ clustering overcomes the limitations of reference databases by
considering only sequences in the dataset, but is more computationally intensive
and generates different OTU assignments when new sequences are introduced.
Unstable OTU assignments make it difficult to use _de novo_ clustering to
compare taxonomic composition of communities between studies or to use machine
learning models trained with _de novo_ OTUs to make predictions on new data.
Open reference methods take a hybrid approach, first performing closed reference
clustering, then any sequences that cannot be assigned to reference OTUs are
clustered _de novo_ to create additional OTUs.
Previous studies found that the OptiClust _de novo_ clustering algorithm created
the highest quality OTU assignments of all clustering methods based on the
Matthews correlation coefficient (MCC) [@westcott_opticlust_2017].
As a result, we have recommended OptiClust as the preferred method for OTU
clustering whenever OTU stability is not required.

- **TODO: current method for open/closed is vsearch against greengenes.**
- **TODO: use word "map" for what vsearch does, "fit" for what optifit does.**
- **TODO**: 2 categories of clustering: _de novo_ and reference based. separate paragraphs. describe opticlust first in de novo paragraph. 2nd paragraph: ref methods are good cause they're fast and don't use much ram. dependent on order of db. people use greengenes, which are rep seqs from 3% otus from full length.
- reader should know what opticlust is, closed & open ref clustering is, strengths & weakness are of each. then we solve these problems.
- **TODO:** note that greengenes is defunct now?!

To overcome the limitations of _de novo_ clustering while maintaining OTU
quality, we developed OptiFit, a reference-based clustering algorithm in the
mothur program which takes existing OTUs as the reference to fit new sequences
to. 
**TODO: more words here?** 
Here, we tested the OptiFit algorithm with the reference as a database or _de
novo_ OTUs and compared the performance to existing tools.
To evaluate the OptiFit algorithm and compare to existing methods, we used four
published datasets isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples. 

## Results

### The OptiFit algorithm

OptiFit leverages the method employed by OptiClust of iteratively assigning
sequences to OTUs to produce the highest quality OTUs possible, and extends this
method for reference-based clustering.
**TODO: brief description of the opticlust algorithm.**
OptiFit begins where OptiClust ends, starting with a list of reference OTUs and
their sequences, a list of query sequences to assign to the reference OTUs, and
the sequence pairs that are within the distance threshold (e.g. 0.03).
Initially, query sequences are placed in singleton OTUs. 
Then, the algorithm iteratively reassigns the query sequences to the reference 
OTUs to optimize the Matthews correlation coefficient (MCC). 
Alternatively, a sequence will remain unassigned if the MCC value is maximized
when the sequence is a singleton rather than assigned to a reference OTU.
This process is repeated until the MCC changes by no more than 0.0001 (default)
or until a maximum number of iterations is reached (default: 100).
In the closed reference mode, any query sequences that cannot be assigned to
references OTUs are discarded, and the results will only contain OTUs that exist
in the original reference.
In the open reference mode, unassigned query sequences are clustered _de novo_
using OptiClust to generate new OTUs.
The final MCC is reported with the best OTU assignments.
There are two strategies for generating OTUs with OptiFit: 
1) fit query sequences to reference OTUs generated by _de novo_ clustering an
independent database, or
2) split the dataset into a reference and query fraction, cluster the reference
sequences _de novo_, then fit the query sequences to the reference OTUs.
**TODO: describe data sets here**

### Reference clustering with public databases

While _de novo_ clustering produces high quality OTUs, researchers may prefer to
perform reference clustering to a public database because reference-based
methods produce consistent OTUs and are generally faster than _de novo_ methods.
In closed reference mode, sequences that cannot be assigned to reference OTUs
are thrown out, so that the final clustering contains only OTUs that exist in
the reference.
To test how OptiFit performs for this purpose, we fit each dataset to three
databases of reference OTUs: the Greengenes database, the SILVA non-redundant
database, and the Ribosomal Database Project (RDP) [@desantis_greengenes_2006;
@quast_silva_2013; @cole_ribosomal_2014].
Reference OTUs for each database were created by performing _de novo_ clustering
with OptiClust at a distance threshold of 3%.
The _de novo_ MCC scores for the three databases were **TODO**.
Fitting sequences to Greengenes and SILVA in closed reference mode performed
similarly, with median MCC scores of `r closed_fit_gg_mcc` and 
`r closed_fit_silva_mcc` respectively, while the median MCC 
dropped to `r closed_fit_rdp_mcc` when fitting to RDP.
For comparison, clustering datasets _de novo_ with
OptiClust produced an average MCC score of `r opticlust_mcc`.
This gap in OTU quality mostly disappeared when clustering in open reference
mode, which produced median MCCs of `r open_fit_gg_mcc` with greengenes, 
`r open_fit_silva_mcc` with SILVA, and `r open_fit_rdp_mcc` with RDP.
Thus, open reference OptiFit produced OTUs of very similar quality as _de novo_
clustering, and closed reference OptiFit followed closely behind as long as a
suitable reference database was chosen.

Since closed reference clustering does not cluster query sequences that could
not be assigned to reference OTUs, an additional measure of clustering
performance to consider is the fraction of query sequences that were able to be
assigned.
On average, more sequences were assigned with Greengenes as the reference 
(`r frac_fit_gg`%) than with SILVA (`r frac_fit_silva`%) or RDP (`r frac_fit_rdp`%).
This mirrored the result reported above that Greengenes produced better OTUs in
terms of MCC score than either SILVA or RDP.
Note that _de novo_ and open reference clustering methods always assign 100% of
sequences to OTUs.
The database chosen affects the final OTU assignments considerably in terms of
both MCC score and fraction of query sequences that could be fit to the
reference OTUs.

Despite the drawbacks, closed reference methods have been used when fast
execution speed is required such as when using very large datasets.
To compare performance in terms of speed, we repeated each OptiFit and OptiClust
run 100 times and measured the execution time.
Closed reference OptiFit outperformed both OptiClust and open reference OptiFit,
with average run times of `r closed_fit_db_sec`, `r opticlust_sec`,
and `r open_fit_db_sec` seconds, respectively.
**TODO: don't average by all datasets & datasets?.**
Thus, the OptiFit algorithm continues the precedent that closed reference
clustering sacrifices OTU quality for execution speed.

To compare to the reference clustering method used by QIIME2, we clustered each
dataset with VSEARCH against the Greengenes database of OTUs previously 
clustered at 97% sequence similarity.
Each reference OTU from the Greengenes 97% database contains one reference
sequence, and VSEARCH maps sequences to the reference based on each individual
sequence's similarity to the single reference OTU.
In contrast, OptiFit accepts reference OTUs, which each may contain multiple
sequences, and the sequence similarity between all query and reference sequences
is considered when assign sequences to OTUs.
_De novo_ clustering with OptiClust produced `r mcc_opticlust_vs_vsearch`%
higher quality OTUs than VSEARCH, but performed `r sec_opticlust_vs_vsearch`% 
slower than VSEARCH.
In closed reference mode, VSEARCH was able to map `r frac_vsearch_vs_fit`% more
query sequences than OptiFit to the Greengenes reference database.
This is because VSEARCH only considers the distances between each query sequence
to the single reference sequence, while OptiFit considers the distances between
all pairs of sequences in an OTU. <!-- VSEARCH "diameter" vs OptiFit "radius"
-->
When open reference clustering, OptiFit produced higher quality OTUs than
VSEARCH against the Greengenes database, with median MCC scores of 
`r open_fit_gg_mcc` and `r open_vsearch_mcc` (respectively).
In terms of run time, OptiFit outperformed VSEARCH in both closed and open
reference mode by `r sec_closed_fit_db_vs_vsearch`% and 
`r sec_vsearch_vs_open_fit_db`% on average respectively.
**TODO: conclude:** The stark difference in OTU definitions between mothur and VSEARCH resulted in...

### Reference clustering with split datasets

When performing reference clustering against public databases, the database 
chosen greatly affects the quality of OTUs produced.
OTU quality may be poor when the reference database is too unrelated to the
samples of interest, such as when samples contain low abundant or novel
populations.
While _de novo_ clustering overcomes the quality limitations of reference
clustering to databases, OTU assignments are not consistent when new sequences are
added.
Researchers may wish to fit new sequences to existing OTUs when comparing OTUs
across studies or when making predictions with machine learning models.
To determine how well OptiFit performs for fitting new sequences to existing
OTUs, we employed a split dataset strategy, where each dataset was randomly
split into a reference fraction and a query fraction.
Reference sequences were clustered _de novo_ with OptiClust, then query
sequences were fit to the _de novo_ OTUs with OptiFit.

First, we tested whether OptiFit performed as well as _de novo_ clustering when
using the split dataset strategy with half of the sequences selected for
the reference by a simple random sample.
OTU quality was highly similar to that from OptiClust regardless of
mode (`r mcc_opticlust_vs_fit_split_simple`% difference in median MCC).
In closed reference mode, OptiFit was able to fit `r frac_fit_split`% of query
sequences to reference OTUs with the split strategy, a great improvement over
the average `r frac_fit_gg`% of sequences fit to the greengenes database.
In terms of runtime, closed and open reference OptiFit performed faster than
OptiClust on whole datasets by `r sec_closed_fit_split_vs_clust`% and 
`r sec_open_fit_split_vs_clust` respectively.
The split dataset strategy also performed `r sec_closed_fit_split_vs_db`% faster
than the database strategy in closed reference mode and 
`r sec_open_fit_split_vs_db`% faster in open reference mode.
Thus, reference clustering with the split dataset strategy creates as high
quality OTUs as _de novo_ clustering yet at a faster run time, and fits far more
query sequences than the database strategy.

**Then we wanted to know; what fraction of sequences should be in the reference?**
To test the best reference size, reference sizes from 10% to 80% of the
sequences were created, with the remaining sequences used for the query.
OTU quality was remarkably stable across reference fraction sizes.
For example, splitting the human dataset 100 times yielded a coefficient of
variation of `r cv_fit_split_mcc_human` for the MCC score across all fractions. **TODO: revisit how to report this**

**Finally, we wanted to know the best way to select the reference sequences.**
**TODO: pick a fraction (e.g. 50%). this part is less important. figure would be supplemental.**
We also tested three methods for selecting the fraction of sequences to be used
as the reference; a simple random sample, weighting sequences by relative
abundance, and weighting by similarity to other sequences in the dataset.
OTU quality was similar with the simple and abundance-weighted sampling (median
MCCs `r mcc_fit_split_simple` and `r mcc_fit_split_abun` respectively), but
worse for similarity-weighted sampling with a median MCC of `r mcc_fit_split_dist`.
In closed reference mode, the fraction of query sequences that can be fit to the
reference OTUs increases as the reference fraction increases; from 
`r frac_fit_split_0.1`% of query sequences fit when using 10% of the dataset as 
the reference, to `r frac_fit_split_0.8`% of query sequences fit when using 80% 
of the dataset as the reference.


## Discussion

We developed a new algorithm for fitting sequences to existing OTUs and have
demonstrated its suitability for reference-based clustering.
OptiFit makes the iterative method employed by OptiClust available for tasks
where reference-based clustering is required.
We have shown that OTU quality is similar between OptiClust and OptiFit in open
reference mode, regardless of strategy employed.
Open reference OptiFit performs slower than OptiClust due to the additional _de
novo_ clustering step, so users may prefer OptiClust for tasks that do not
require reference OTUs.

When fitting to public databases, OTU quality dropped in closed reference mode
to different degrees depending on the database and dataset source, and no more
than half of query sequences were able to be fit to OTUs across any
dataset/database combination. 
This may reflect limitations of reference
databases, which are unlikely to contain sequences from rare and novel microbes.
This drop in quality was most notable with RDP, which contains only about 21,000
sequences compared to over 200,000 sequences in SILVA and Greengenes each at the
time of this writing.
We recommend that users who require an independent reference database opt for
large databases with good coverage of microbial diversity.
Since OptiClust performs faster than open reference OptiFit and creates higher
quality OTUs than closed reference OptiFit with the database strategy, we
recommend using OptiClust rather than fitting to a database whenever stable OTUs
are not required for the study at hand.

The OptiClust and OptiFit algorithms provided by mothur produced higher quality
OTUs than VSEARCH in open reference, closed reference, or _de novo_ modes.
However, VSEARCH was able to map more sequences to OTUs than OptiFit in closed
reference mode.
While both mothur and VSEARCH use a distance or similarity threshold for
determining how to assign sequences to OTUs, VSEARCH is more permissive than
mothur.
The OptiFit and OptiClust algorithms use all of the sequences to define an
OTU, requiring that all pairs of sequences (including reference and query
sequences) in an OTU are within the distance threshold without penalizing the
MCC.
In contrast, VSEARCH only requires each query sequence to be similar to the
single sequence that seeded the OTU.
In this way, VSEARCH sacrifices OTU quality in order to allow more sequences to
fit to OTUs.
Users who require closed reference clustering to the Greengenes database may
prefer to use VSEARCH if they wish to maximize the fraction of sequences that
can be fit at the cost of OTU quality.
However, mothur's OptiClust or OptiFit are recommended for _de novo_ or open
reference clustering to produce OTUs of the highest possible quality.

When fitting with the split dataset strategy, OTU quality was remarkably similar
when reference sequences were selected by a simple random sample or weighted by
abundance, but quality was slightly worse when sequences were weighted by
similarity. 
We recommend using a simple random sample since the more
sophisticated reference selection methods do not offer any benefit. 
The similarity in OTU quality between OptiClust and OptiFit with this strategy
demonstrates the suitability of using OptiFit to fit sequences to existing OTUs,
such as when using already-trained machine learning models to make predictions
on new data or comparing OTUs across studies.
However, when stable OTUs are not required, we recommend using OptiClust for _de
novo_ clustering over the split strategy with OptiFit since OptiClust is simpler
to execute but performs similarly in terms of both run time and OTU quality.

**TODO: big picture concluding paragraph.**
We have developed a new clustering algorithm that allows users to produce high
quality OTUs using already existing OTUs as a reference.
**TODO: Point to courtney's paper metaphorically. wow what a cool application someone should do _wink wink_.**

## Materials and Methods

### Data Processing Steps

We downloaded 16S rRNA gene amplicon sequences from four published datasets
isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples.
Raw sequences were processed using mothur according to the Schloss Lab MiSeq SOP
as described in the mothur wiki and accompanying study by Kozich _et al._
[@schloss_miseq_nodate; @kozich_development_2013].
These steps included trimming and filtering for quality, aligning to the SILVA
reference alignment [@quast_silva_2013], discarding sequences that aligned
outside the V4 region, removing chimeric reads with UCHIME [@edgar_uchime_2011],
and calculating distances between all pairs of sequences within each dataset
prior to clustering.

### Reference database clustering

To generate reference OTUs from independent databases, we downloaded sequences
from the Greengenes database (v13_8_99) [@desantis_greengenes_2006], SILVA
non-redundant database (v132) [@quast_silva_2013], and the Ribosomal Database
Project (v16) [@cole_ribosomal_2014].
These sequences were processed using the same steps outlined above followed by
clustering sequences into _de novo_ OTUs with OptiClust.
Processed reads from each of the four datasets were clustered with OptiFit to
the reference OTUs generated from each of the three databases.
When reference clustering with VSEARCH, processed datasets were fit directly to
the unprocessed Greengenes reference alignment, since this method is how VSEARCH
is typically used by the QIIME2 software reference-based clustering
[@bolyen_reproducible_2019; @noauthor_clustering_nodate].

### Split dataset clustering

For each dataset, a fraction of the sequences was selected to be clustered _de
novo_ into reference OTUs with OptiClust.
We used three methods for selecting the fraction of sequences to be used
as the reference; a simple random sample, weighting sequences by relative
abundance, and weighting by similarity to other sequences in the dataset.
Dataset splitting was repeated with reference fractions ranging from 10% to 80%
of the dataset and for 100 random seeds.
For each dataset split, the remaining sequences were assigned to the reference
OTUs with OptiFit.

### Benchmarking

Since OptiClust and OptiFit employ a random number generator to break ties
when OTU assignments are of equal quality, they produce slightly different OTU
assignments when repeated with different random seeds.
To capture any variation in OTU quality or execution time, clustering was
repeated with 100 random seeds for each combination of parameters and
input datasets.
We used the benchmark feature provided by Snakemake to measure the run time of
every clustering job.
We calculated the MCC on each set of OTUs to quantify the quality of clustering,
as described by Westcott _et al._ [@westcott_opticlust_2017].

### Data and Code Availability

We implemented the analysis workflow in Snakemake [@koster_snakemake_2012] and
wrote scripts in R [@r_core_team_r_2020], Python [@van_rossum_python_2009], and
GNU bash [@noauthor_bash_nodate].
Software used includes mothur v1.45.0 [@schloss_introducing_2009], VSEARCH
v2.13.3 [@rognes_vsearch_2016], numpy [@harris_array_2020], the Tidyverse
metapackage [@wickham_welcome_2019], R Markdown [@xie_r_2018], the SRA toolkit
[@noauthor_sra-tools_nodate], and the conda environment manager
[@noauthor_anaconda_2016].
The complete workflow, manuscript, and conda environment are available at
**TODO: UPDATED REPO LINK**.

## Acknowledgements {.appendix}

KLS received support from the NIH Training Program in Bioinformatics (T32 GM070449).

PDS received support from **TODO: Pat's grant(s)**.

The funders had no role in study design, data collection and interpretation, 
or the decision to submit the work for publication.

## Author Contributions {.appendix}

KLS wrote the analysis code, evaluated the algorithm, and wrote the original draft of the manuscript.
SLW designed and implemented the OptiFit algorithm and assisted in debugging the analysis code.
MBM and GAD contributed analysis code.
PDS conceived the study, supervised the project, and assisted in debugging the analysis code.
All authors reviewed and edited the manuscript.