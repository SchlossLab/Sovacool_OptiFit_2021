---
title: "OptiFit: a fast method for fitting amplicon sequences to existing OTUs"
date: '`r Sys.Date()`'
authors:
  - name: "Kelly L. Sovacool"
    url: https://github.com/kelly-sovacool
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
    orcid_id: 0000-0003-3283-829X
  - name: "Sarah L. Westcott"
    url: https://github.com/mothur-westcott
    affiliation: Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
  - name: "M. Brodie Mumphrey"
    url: https://github.com/MBMumphrey
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
  - name: "Gabrielle A. Dotson"
    url: https://github.com/dotsonga
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
  - name: "Patrick D. Schloss"
    url: https://github.com/pschloss
    affiliation: Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
bibliography: references.bib
output:
  distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
  pdf_document:
    keep_tex: false
    includes:
      in_header: preamble.tex
      before_body: head.tex
      after_body: tail.tex
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs", output_format = "all") })
csl: msystems.csl
fontsize: 12pt
geometry: margin=1.0in
repository_url: https://github.com/SchlossLab/OptiFitAnalysis
creative_commons: CC BY-SA
twitter:
  creator: "@kelly_sovacool"
  site: "@PatSchloss"
---

```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE}
mothuR::set_knitr_opts()
```

```{r deps, message = FALSE}
library(here)
library(mothuR)
library(tidyverse)
dat <- read_tsv(here('results', 'summarized.tsv'))
rel_diff <- function(final, init, percent = TRUE) {
  mult <- if (isTRUE(percent)) 100 else 1
  return((final - init) / init * mult)
}
```

## Abstract

Assigning amplicon sequences to Operational Taxonomic Units (OTUs) is an
important step in characterizing the composition of microbial communities across
large datasets.
OptiClust, a _de novo_ OTU clustering method in the mothur program, has been
shown to produce higher quality OTU assignments than other methods and at
comparable or faster speeds [@westcott_opticlust_2017;
@schloss_introducing_2009].
A notable difference between _de novo_ clustering and database-dependent methods
is that OTU assignments clustered with _de novo_ methods are not stable when new
sequences are added to a dataset [@westcott_novo_2015].
However, in some cases one may wish to incorporate new samples into a previously
clustered dataset without performing clustering again on all sequences, such as
when deploying a machine learning model where OTUs are features
[@topcuoglu_effective_2019].
To provide an efficient and robust method to fit amplicon sequence data to
existing OTUs, we developed the OptiFit algorithm as a new component of the
mothur program.

**TODO: summarize results & conclusion**

### Importance

**TODO**

\newpage

## Introduction

Amplicon sequencing has become a mainstay of microbial ecology and
host-associated microbiome research.
Researchers can affordably generate millions of sequences to characterize the
composition of hundreds of samples from culture-independent microbial
communities. In a typical analysis pipeline,
16S rRNA gene sequences are assigned to Operational Taxonomic Units (OTUs) to
facilitate comparison of taxonomic composition between communities.
A distance threshold of 3% (or sequence similarity of 97%) is commonly used to
cluster sequences into OTUs based on either a reference database or pairwise
comparisons of the sequences within the dataset.
The method chosen for clustering affects the quality of OTU assignments and thus
may impact downstream analyses of community composition
[@westcott_opticlust_2017; @schloss_application_2016;
@westcott_novo_2015].

There are three main categories of OTU clustering algorithms: closed reference,
open reference, and _de novo_ clustering. 
Closed reference methods assign sequences to a set of pre-made OTUs generated
from reference sequences.
If a query sequence is not within the distance threshold to any of the reference
sequences, it is discarded.
While reference-based clustering is generally fast, it is limited by the
diversity of the reference database.
Rare or novel sequences in the sample will be lost if they are not represented
by a similar sequence in the database.
_De novo_ methods cluster sequences based on their distance to each other,
without the use of an external reference.
_De novo_ clustering overcomes the limitations of reference databases by
considering only sequences in the dataset, but is more computationally intensive
and generates different OTU assignments when new sequences are introduced.
Unstable OTU assignments make it difficult to use _de novo_ clustering to
compare taxonomic composition of communities between studies or to use machine
learning models trained with _de novo_ OTUs to make predictions on new data.
Open reference methods take a hybrid approach, first performing closed reference
clustering, then any sequences that cannot be assigned to reference OTUs are
clustered _de novo_ to create additional OTUs.
Previous studies found that the OptiClust _de novo_ clustering algorithm created
the highest quality OTU assignments of all clustering methods based on the
Matthews correlation coefficient (MCC) [@westcott_opticlust_2017].
As a result, we have recommended OptiClust as the preferred method for OTU
clustering whenever OTU stability is not required.

To overcome the limitations of _de novo_ clustering while maintaining OTU
quality, we developed OptiFit, a reference-based clustering algorithm in the
mothur program which takes existing OTUs as the reference to fit new sequences
to. 
**TODO: more words here?** 
Here, we tested the OptiFit algorithm with the reference as a database or _de
novo_ OTUs and compared the performance to existing tools.


## Results

### The OptiFit algorithm

**TODO: ask Sarah Westcott to check the accuracy of this description**

OptiFit leverages the method employed by OptiClust of iteratively assigning
sequences to OTUs to produce the highest quality OTUs possible, and extends this
method for reference-based clustering.
OptiFit takes as input a list of reference OTUs and their sequences, a list of
query sequences to assign to the reference OTUs, the sequence pairs that are
within the distance threshold (e.g. 0.03), and the metric to assess clustering
quality (default: MCC).
Query sequences are randomly seeded in reference OTUs, then for each sequence
the algorithm calculates the quality metric based on whether the sequence stays
in its current OTU or moves to each of the other OTUs.
If two or more OTU assignments are of equal quality, a random number generator
is used to break the tie.
This process is repeated until the quality metric stabilizes, changing by no
more than 0.0001 by default, or until a maximum number of iterations is reached
(default: 100).
In closed-reference mode, any query sequences that cannot be assigned are thrown
out (**TODO: exactly what determines whether a seq can't be assigned?**), and
the results only contain OTUs that exist in the original reference.
In open-reference mode, unassigned query sequences are clustered _de novo_ using
OptiClust to generate additional OTUs. The final quality score is reported with
the best OTU assignments.

To evaluate the OptiFit algorithm and compare to existing methods, we used four
published datasets isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples. 
There are two strategies for generating OTUs with OptiFit: 1) fit sequences to
reference OTUs of an independent database, or 2) split the dataset into a
reference and query fraction, cluster the reference sequences _de novo_, then
fit the query sequences to the reference OTUs.
For each dataset repeated with 100 random seeds, we generated OTUs with OptiFit
using both strategies.
To compare to existing software, we also clustered OTUs _de novo_ using
OptiClust and VSEARCH, and with VSEARCH in reference-based mode against the
Greengenes database.
All clustering was performed at a distance threshold of 0.03 and OTU quality was
evaluated using the MCC as described previously [@westcott_opticlust_2017].
We calculated the fraction of query sequences that were fit to existing OTUs in
closed reference mode as an additional measure of quality for this mode.

### Reference clustering with public databases

```{r ref_db}
open_fit_mcc <- dat %>% filter(method == 'open', strategy == 'database', tool == 'mothur') %>% pull(mcc_median) %>% median()
opticlust_mcc <- dat %>% filter(method == 'de_novo', tool == 'mothur') %>% pull(mcc_median) %>% median()
open_fit_db_vs_clust <- rel_diff(opticlust_mcc, open_fit_mcc)

open_fit_gg_mcc <- dat %>% filter(method == 'open', strategy == 'database', tool == 'mothur', ref == 'gg') %>% pull(mcc_median) %>% median()
open_vsearch_mcc <- dat %>% filter(method == 'open', strategy == 'database', tool == 'vsearch', ref == 'gg') %>% pull(mcc_median) %>% median()
open_fit_db_vs_vsearch <- rel_diff(open_fit_gg_mcc, open_vsearch_mcc)
```


To evaluate reference-based clustering with independent databases, we fit each
dataset to reference OTUs generated by _de novo_ clustering the Greengenes
database, SILVA non-redundant database, or the Ribosomal Database Project (RDP)
[@desantis_greengenes_2006; @quast_silva_2013; @cole_ribosomal_2014].

In open reference mode, fitting the datasets to reference OTUs with OptiFit
produced OTUs of similar quality (`r open_fit_db_vs_clust`% difference in median
MCC) as clustering the datasets _de novo_ with OptiClust  across all datasets
and reference databases.
OptiFit produced higher quality OTUs than VSEARCH when open reference clustering
against the Greengenes database, with median MCC scores of `r open_fit_gg_mcc`
and `r open_vsearch_mcc` (respectively).
However, open reference VSEARCH and OptiClust respectively ran **X%** and **Y%**
faster than OptiFit in open reference mode.
_De novo_ clustering with OptiClust produced **X%** higher quality OTUs than
VSEARCH, but performed **Y%** slower than VSEARCH.

In closed reference mode, OptiFit produced lower quality OTUs than OptiClust by
**X%** when fitting sequences to Greengenes and SILVA, and **Y%** worse when
fitting to RDP.
Only up to **Z%** of query sequences were fit to reference OTUs in closed
reference mode across any dataset/database combination.
OptiFit was able to fit **X** more query sequences to reference OTUs created
with the Greengenes and SILVA databases than with RDP.
VSEARCH was able to fit **W%** more query sequences to the Greengenes reference
than OptiFit in closed reference mode.
In terms of run time, closed reference OptiFit outperformed
OptiClust by **A%** and VSEARCH by **B%**.

### Reference clustering with split datasets

A split dataset strategy was employed to assess how well OptiFit performs for
tasks where new sequences are added to existing OTUs, such as when comparing
OTUs across studies or making predictions with machine learning models.
Datasets were randomly split into a reference fraction and a query fraction.
Reference sizes from 10% to 80% of the sequences were created, with the
remaining sequences used for the query.
Reference sequences were clustered _de novo_ with OptiClust, then query
sequences were fit to the _de novo_ OTUs with OptiFit.

OTU quality from the split dataset strategy with OptiFit was highly similar to
that from _de novo_ clustering the whole dataset with OptiClust regardless of
mode (**TODO: diff in MCC medians**).
OTU quality was remarkably stable across 100 different random seeds (**TODO:
variation or stdev?**).
In terms of runtime, closed reference OptiFit performed faster than OptiClust on
whole datasets by **Z%**.
In open reference mode, OptiClust performed **X to Y%** faster than OptiFit only
when the OptiFit reference fraction was 30% or less.
The split dataset strategy performed just as well as the database strategy in
open reference mode regardless of database used, and outperformed the database
strategy in closed reference mode by **W%**.

We also tested three methods for selecting the fraction of sequences to be used
as the reference; a simple random sample, weighting sequences by relative
abundance, and weighting by similarity to other sequences in the dataset.
OTU quality was similar with the simple and abundance-weighted sampling (median
MCCs **X** and **Y** respectively), but **Z%** worse with similarity-weighted
sampling.
In closed reference mode, the fraction of query sequences that can be fit to the
reference OTUs decreases as the reference fraction increases from an MCC of
**A** with **J** reference sequences to an MCC of **B** with **K** reference
sequences.

## Discussion

We developed a new algorithm for fitting sequences to existing OTUs and have
demonstrated its suitability for reference-based clustering.
OptiFit makes the iterative method employed by OptiClust available for tasks
where reference-based clustering is required.
We have shown that OTU quality is similar between OptiClust and OptiFit in open
reference mode, regardless of strategy employed.
Open reference OptiFit performs slower than OptiClust due to the additional _de
novo_ clustering step, so users may prefer OptiClust for tasks that do not
require reference OTUs.

When fitting to public databases, OTU quality dropped in closed reference mode
to different degrees depending on the database and dataset source, and no more
than half of query sequences were able to be fit to OTUs across any
dataset/database combination. 
This may reflect limitations of reference
databases, which are unlikely to contain sequences from rare and novel microbes.
This drop in quality was most notable with RDP, which contains only about 21,000
sequences compared to over 200,000 sequences in SILVA and Greengenes each at the
time of this writing.
We recommend that users who require an independent reference database opt for
large databases with good coverage of microbial diversity.
Since OptiClust performs faster than open reference OptiFit and creates higher
quality OTUs than closed reference OptiFit with the database strategy, we
recommend using OptiClust rather than fitting to a database whenever stable OTUs
are not required for the study at hand.

The OptiClust and OptiFit algorithms provided by mothur produced higher quality
OTUs than VSEARCH in open reference, closed reference, or _de novo_ modes.
However, VSEARCH was able to fit more sequence into OTUs than OptiFit in closed
reference mode.
While both mothur and VSEARCH use a distance or similarity threshold for
determining how to assign sequences to OTUs, VSEARCH is more permissive than
mothur.
Mothur's OptiFit and OptiClust algorithms use all of the sequences to define an
OTU, requiring that all pairs of sequences (including reference and query
sequences) in an OTU are within the distance threshold without penalizing the
MCC.
In contrast, VSEARCH only requires each query sequence to be similar to the
single sequence that seeded the OTU.
In this way, VSEARCH sacrifices OTU quality in order to allow more sequences to
fit to OTUs.
Users who require closed reference clustering to the Greengenes database may
prefer to use VSEARCH if they wish to maximize the fraction of sequences that
can be fit at the cost of OTU quality.
However, mothur's OptiClust or OptiFit are recommended for _de novo_ or open
reference clustering to produce OTUs of the highest possible quality.

When fitting with the split dataset strategy, OTU quality was remarkably similar
when reference sequences were selected by a simple random sample or weighted by
abundance, but quality was slightly worse when sequences were weighted by
similarity. 
We recommend using a simple random sample since the more
sophisticated reference selection methods do not offer any benefit. 
The similarity in OTU quality between OptiClust and OptiFit with this strategy
demonstrates the suitability of using OptiFit to fit sequences to existing OTUs,
such as when using already-trained machine learning models to make predictions
on new data or comparing OTUs across studies.
However, when stable OTUs are not required, we recommend using OptiClust for _de
novo_ clustering over the split strategy with OptiFit since OptiClust is simpler
to execute but performs similarly in terms of both run time and OTU quality.

**TODO: big picture concluding paragraph.**
We have developed a new clustering algorithm that allows users to produce high
quality OTUs using already existing OTUs as a reference.

## Materials and Methods

### Data Processing Steps

We downloaded 16S rRNA gene amplicon sequences from four published datasets
isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples.
Raw sequences were processed using mothur according to the Schloss Lab MiSeq SOP
as described in the mothur wiki and accompanying study by Kozich _et al._
[@schloss_miseq_nodate; @kozich_development_2013].
These steps included trimming and filtering for quality, aligning to the SILVA
reference alignment [@quast_silva_2013], discarding sequences that aligned
outside the V4 region, removing chimeric reads with UCHIME [@edgar_uchime_2011],
and calculating distances between all pairs of sequences within each dataset
prior to clustering.

### Reference database clustering

To generate reference OTUs from independent databases, we downloaded sequences
from the Greengenes database (v13_8_99) [@desantis_greengenes_2006], SILVA
non-redundant database (v132) [@quast_silva_2013], and the Ribosomal Database
Project (v16) [@cole_ribosomal_2014].
These sequences were processed using the same steps outlined above followed by
clustering sequences into _de novo_ OTUs with OptiClust.
Processed reads from each of the four datasets were clustered with OptiFit to
the reference OTUs generated from each of the three databases.
When reference clustering with VSEARCH, processed datasets were fit directly to
the unprocessed Greengenes reference alignment, since this method is how VSEARCH
is typically used by the QIIME2 software reference-based clustering
[@bolyen_reproducible_2019; @noauthor_clustering_nodate].

### Split dataset clustering

For each dataset, a fraction of the sequences was selected to be clustered _de
novo_ into reference OTUs with OptiClust.
We used three methods for selecting the fraction of sequences to be used
as the reference; a simple random sample, weighting sequences by relative
abundance, and weighting by similarity to other sequences in the dataset.
Dataset splitting was repeated with reference fractions ranging from 10% to 80%
of the dataset and for 100 random seeds.
For each dataset split, the remaining sequences were assigned to the reference
OTUs with OptiFit.

### Benchmarking

Since OptiClust and OptiFit employ a random number generator to break ties
when OTU assignments are of equal quality, they produce slightly different OTU
assignments when repeated with different random seeds.
To capture any variation in OTU quality or execution time, clustering was
repeated with 100 random seeds for each combination of parameters and
input datasets.
We used the benchmark feature provided by Snakemake to measure the run time of
every clustering job.
We calculated the MCC on each set of OTUs to quantify the quality of clustering,
as described by Westcott _et al._ [@westcott_opticlust_2017].

### Data and Code Availability

We implemented the analysis workflow in Snakemake [@koster_snakemake_2012] and
wrote scripts in R [@r_core_team_r_2020], Python [@van_rossum_python_2009], and
GNU bash [@noauthor_bash_nodate].
Software used includes mothur v1.45.0 [@schloss_introducing_2009], VSEARCH
v2.13.3 [@rognes_vsearch_2016], numpy [@harris_array_2020], the Tidyverse
metapackage [@wickham_welcome_2019], R Markdown [@xie_r_2018], the SRA toolkit
[@noauthor_sra-tools_nodate], and the conda environment manager
[@noauthor_anaconda_2016].
The complete workflow, manuscript, and conda environment are available at
**TODO: UPDATED REPO LINK**.

## Acknowledgements {.appendix}

KLS received support from the NIH Training Program in Bioinformatics (T32 GM070449).

PDS received support from **TODO: Pat's grant(s)**.

The funders had no role in study design, data collection and interpretation, 
or the decision to submit the work for publication.

## Author Contributions {.appendix}

KLS wrote the analysis code, evaluated the algorithm, and wrote the original draft of the manuscript.
SLW designed and implemented the OptiFit algorithm and assisted in debugging the analysis code.
MBM and GAD contributed analysis code.
PDS conceived the study, supervised the project, and assisted in debugging the analysis code.
All authors reviewed and edited the manuscript.