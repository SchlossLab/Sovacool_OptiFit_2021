---
title: "OptiFit: a fast method for fitting amplicon sequences to existing OTUs"
date: '`r Sys.Date()`'
authors:
  - name: "Kelly L. Sovacool"
    url: https://github.com/kelly-sovacool
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
    orcid_id: 0000-0003-3283-829X
  - name: "Sarah L. Westcott"
    url: https://github.com/mothur-westcott
    affiliation: Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
  - name: "M. Brodie Mumphrey"
    url: https://github.com/MBMumphrey
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
  - name: "Gabrielle A. Dotson"
    url: https://github.com/dotsonga
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
  - name: "Patrick D. Schloss"
    url: https://github.com/pschloss
    affiliation: Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
bibliography: references.bib
output:
  distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
  pdf_document:
    keep_tex: false
    includes:
      in_header: preamble.tex
      before_body: head.tex
      after_body: tail.tex
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs", output_format = "all") })
csl: msystems.csl
fontsize: 12pt
geometry: margin=1.0in
repository_url: https://github.com/SchlossLab/OptiFitAnalysis
creative_commons: CC BY-SA
twitter:
  creator: "@kelly_sovacool"
  site: "@PatSchloss"
---

```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE}
mothuR::set_knitr_opts()
```

## Abstract

Assigning amplicon sequences to Operational Taxonomic Units (OTUs) is an
important step in characterizing the composition of microbial communities across
large datasets. OptiClust, a _de novo_ OTU clustering method in the mothur
program, has been shown to produce higher quality OTU assignments than other
methods and at comparable or faster speeds [@westcott_opticlust_2017;
@schloss_introducing_2009]. A notable difference between _de novo_ clustering
and database-dependent methods is that OTU assignments clustered with _de novo_
methods are not stable when new sequences are added to a dataset
[@westcott_novo_2015]. However, in some cases one may wish to incorporate new
samples into a previously clustered dataset without performing clustering again
on all sequences, such as when deploying a machine learning model where OTUs are
features [@topcuoglu_effective_2019]. To provide an efficient and robust method
to fit amplicon sequence data to existing OTUs, we developed the OptiFit
algorithm as a new component of the mothur program.

- **TODO: summarize results & conclusion**

### Importance

**TODO**

\newpage

## Introduction

Amplicon sequencing has become a mainstay of microbial ecology and
host-associated microbiome research. Researchers can affordably generate
millions of sequences to characterize the composition of hundreds of samples
from culture-independent microbial communities. In a typical analysis pipeline,
16S rRNA gene sequences are assigned to Operational Taxonomic Units (OTUs) to
facilitate comparison of taxonomic composition between communities. A distance
threshold of 3% (or sequence similarity of 97%) is commonly used to cluster
sequences into OTUs based on either a reference database or pairwise comparisons
of the sequences within the dataset. The method chosen for clustering affects
the quality of OTU assignments and thus may impact downstream analyses of
community composition [@westcott_opticlust_2017; @schloss_application_2016;
@westcott_novo_2015].

There are three main categories of OTU clustering algorithms: closed reference,
open reference, and _de novo_ clustering. Closed reference methods assign
sequences to a set of pre-made OTUs generated from reference sequences. If a
query sequence is not within the distance threshold to any of the reference
sequences, it is discarded. While reference-based clustering is generally fast,
it is limited by the diversity of the reference database. Rare or novel
sequences in the sample will be lost if they are not represented by a similar
sequence in the database. _De novo_ methods cluster sequences based on their
distance to each other, without the use of an external reference. _De novo_
clustering overcomes the limitations of reference databases by considering only
sequences in the dataset, but is more computationally intensive and generates
different OTU assignments when new sequences are introduced. Unstable OTU
assignments make it difficult to use _de novo_ clustering to compare taxonomic
composition of communities between studies or to use machine learning models
trained with _de novo_ OTUs to make predictions on new data. Open reference
methods take a hybrid approach, first performing closed reference clustering,
then any sequences that cannot be assigned to reference OTUs are clustered _de
novo_ to create additional OTUs. Previous studies found that the OptiClust _de
novo_ clustering algorithm created the highest quality OTU assignments of all
clustering methods based on the Matthews correlation coefficient (MCC)
[@westcott_opticlust_2017]. As a result, we have recommended OptiClust as the
preferred method for OTU clustering whenever OTU stability is not required.

To overcome the limitations of _de novo_ clustering while maintaining OTU
quality, we developed OptiFit, a reference-based clustering algorithm in the
mothur program which takes existing OTUs as the reference to fit new sequences
to. **TODO: more words here?** 
Here, we tested the OptiFit algorithm with the reference as a database or _de
novo_ OTUs and compared the performance to existing tools.


## Results

### The OptiFit algorithm

- **TODO: ask Sarah Westcott to check the accuracy of this description**

OptiFit leverages the method employed by OptiClust of iteratively assigning
sequences to OTUs to produce the highest quality OTUs possible, and extends this
method for reference-based clustering. OptiFit takes as input a list of
reference OTUs and their sequences, a list of query sequences to assign to the
reference OTUs, the sequence pairs that are within the distance threshold (e.g.
0.03), and the metric to assess clustering quality (default: MCC). Query
sequences are randomly seeded in reference OTUs, then for each sequence the
algorithm calculates the quality metric based on whether the sequence stays in
its current OTU or moves to each of the other OTUs. This process is repeated
until the quality metric stabilizes, changing by no more than 0.0001 by default,
or until a maximum number of iterations is reached (default: 100). In
closed-reference mode, any query sequences that cannot be assigned are thrown
out (**TODO: exactly what determines whether a seq can't be assigned?**), and
the results only contain OTUs that exist in the original reference. In
open-reference mode, unassigned query sequences are clustered _de novo_ using
OptiClust to generate additional OTUs. The final quality score is reported with
the best OTU assignments.

To evaluate the OptiFit algorithm and compare to existing methods, we used four
published datasets isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples. There are two strategies for
generating OTUs with OptiFit: 1) fit sequences to reference OTUs of an
independent database, or 2) split the dataset into a reference and query
fraction, cluster the reference sequences _de novo_, then fit the query
sequences to the reference OTUs. For each dataset repeated with 100 random
seeds, we generated OTUs with OptiFit using both strategies. To compare to
existing software, we also clustered OTUs _de novo_ using OptiClust and vsearch,
and with vsearch in reference-based mode against the greengenes database. All
clustering was performed at a distance threshold of 0.03 and OTU quality was
evaluated using the Matthews Correlation Coefficient (MCC) as described
previously [@westcott_opticlust_2017]. We calculated the fraction of query
sequences that were fit to existing OTUs in closed reference mode as an
additional measure of quality for this mode. _De novo_ clustering with OptiFit
produced **X%** higher quality OTUs than vsearch, but performed **Y%** slower
than vsearch.

### Reference clustering with public databases

To evaluate reference-based clustering with independent databases, we fit each
dataset to reference OTUs generated by _de novo_ clustering the Greengenes
database (v13_8_99), Silva non-redundant database (v132), or the Ribosomal
Database Project (RDP; v16). **TODO: cite database papers?** In open reference
mode, fitting the datasets to reference OTUs with OptiFit produced OTUs of
similar quality as clustering the datasets _de novo_ with OptiClust (**TODO:
diff. in medians**). This held true for all datasets and reference databases.
OptiFit produced higher quality OTUs than vsearch when open reference clustering
against the greengenes database, with median MCC scores of **A** and **B%**
(respectively). However, open reference vsearch and OptiClust respectively ran
**X%** and **Y%** faster than OptiFit in open reference mode.

In closed reference mode, OptiFit produced lower quality OTUs than OptiClust by
**X%** when fitting sequences to Greengenes and Silva, and **Y%** worse when
fitting to RDP. Only up to **Z%** of query sequences were fit to reference OTUs
in closed reference mode across any dataset/database combination. OptiFit was
able to fit **X** more query sequences to reference OTUs created with the
Greengenes and Silva databases than with RDP. vsearch was able to fit **W%**
more query sequences to the greengenes reference than OptiFit in closed
reference mode. In terms of run time, closed reference OptiFit outperformed
OptiClust by **A%** and vsearch by **B%**.

### Reference clustering with split datasets

A split dataset strategy was employed to assess how well OptiFit performs for
tasks where new sequences are added to existing OTUs, such as when comparing OTUs
across studies or making predictions with machine learning models.
Datasets were randomly split into a reference fraction and a query fraction.
Reference sizes from 10% to 90% of the sequences were created, with the
remaining sequences used for the query. Reference sequences were clustered _de
novo_ with OptiClust, then query sequences were fit to the _de novo_ OTUs with
OptiFit.

OTU quality from the split dataset strategy with OptiFit was highly similar to
that from _de novo_ clustering the whole dataset with OptiClust regardless of
mode (**TODO: diff in MCC medians**). OTU quality was remarkably stable across
100 different random seeds (**TODO: variation or stdev?**). In terms of runtime,
closed reference OptiFit performed faster than OptiClust on whole datasets by
**Z%**. In open reference mode, OptiClust performed **X to Y%** faster than
OptiFit only when the OptiFit reference fraction was 30% or less. The split
dataset strategy performed just as well as the database strategy in open
reference mode regardless of database used, and outperformed the database
strategy in closed reference mode by **W%**.

We also tested three methods for selecting the fraction of sequences to be used
as the reference; a simple random sample, weighting sequences by relative
abundance, and weighting by similarity to other sequences in the dataset. OTU
quality was similar with the simple and abundance-weighted sampling (median MCCs
**X** and **Y** respectively), but **Z%** worse with similarity-weighted
sampling. In closed reference mode, the fraction of query sequences that can be
fit to the reference OTUs decreases as the reference fraction increases from an
MCC of **A** with **J** reference sequences to an MCC of **B** with **K**
reference sequences.

## Discussion

We developed a new algorithm for fitting sequences to existing OTUs and have
demonstrated its suitability for reference-based clustering. OptiFit makes the
iterative method employed by OptiClust available for tasks where
reference-based clustering is required. We have shown that OTU quality is
similar between OptiClust and OptiFit in open reference mode, regardless of
strategy employed. open reference OptiFit does perform slower than OptiClust
due to the additional _de novo_ clustering step, so users may prefer OptiClust
for tasks that do not require reference OTUs.

When fitting to public databases, OTU quality dropped in closed reference mode
to different degrees depending on the database and dataset source, and no more
than half of query sequences were able to be fit to OTUs across any
dataset/database combination. This may reflect limitations of reference
databases, which are unlikely to contain sequences from rare and novel microbes.
This drop in quality was most notable with RDP, which has only about 16,000 V4
16S sequences compared to about 170,000 in Silva and greengenes. We recommend
users who require an independent reference database opt for large databases with
good coverage of microbial diversity. Since OptiClust performs faster than open
reference OptiFit and creates higher quality OTUs than closed reference OptiFit
with the database strategy, we recommend using OptiClust rather than fitting to
a database whenever stable OTUs are not required for the study at hand.

The mothur algorithms produced higher quality OTUs than vsearch in open
reference, closed reference, or _de novo_ modes. However, vsearch was able to
fit more sequence into OTUs than OptiFit in closed reference mode. While both
mothur and vsearch use a distance or similarity threshold for determining how to
assign sequences to OTUs, vsearch is more permissive than mothur. Mothur's
OptiFit and OptiClust use all of the sequences to define an OTU, requiring that
all pairs of sequences (including reference and query sequences) in an OTU are
within the distance threshold without penalizing the MCC. In contrast, vsearch
only requires each query sequence to be similar to the single sequence that
seeded the OTU. In this way, vsearch sacrifices OTU quality in order to allow
more sequences to fit to OTUs. Users who require closed reference clustering to
the greengenes database may prefer to use vsearch if they wish to maximize the
fraction of sequences that can be fit at the cost of OTU quality. However,
mothur's OptiClust or OptiFit are recommended for _de novo_ or open reference
clustering to produce OTUs of the highest possible quality.

When fitting with the split dataset strategy, OTU quality was remarkably similar
when reference sequences were selected by a simple random sample or weighted by
abundance, but quality was slightly worse when sequences were weighted by
similarity. We recommend using a simple random sample since the more
sophisticated reference selection methods do not offer any benefit. The
similarity in OTU quality between OptiClust and OptiFit with this strategy
demonstrates the suitability of using OptiFit to fit sequences to existing OTUs,
such as when using already-trained machine learning models to make predictions
on new data or comparing OTUs across studies. However, when stable OTUs are not
required, we recommend using OptiClust for _de novo_ clustering over the split
strategy with OptiFit since OptiClust is simpler to execute but performs
similarly in terms of both run time and OTU quality.

- **TODO: big picture concluding paragraph**

## Materials and Methods

### Data Processing Steps 

### Benchmarking

### Data and Code Availability

We implemented the analysis workflow in Snakemake [@koster_snakemake_2012] and
relied on Python [@van_rossum_python_2009], R [@r_core_team_r_2020], and GNU
bash. Software used includes mothur v1.45.0 [@schloss_introducing_2009], vsearch
v2.13.3 [@rognes_vsearch_2016], numpy [@harris_array_2020], the Tidyverse
metapackage [@wickham_welcome_2019], R Markdown [@xie_r_2018], and the conda
environment manager [@noauthor_anaconda_2016]. The complete workflow,
manuscript, and conda environment are available at **TODO: UPDATED REPO LINK**.

## Acknowledgements {.appendix}

KLS received support from the NIH Training Program in Bioinformatics (T32 GM070449).

PDS received support from **TODO: Pat's grant(s)**.

The funders had no role in study design, data collection and interpretation, 
or the decision to submit the work for publication.

## Author Contributions {.appendix}

KLS wrote the analysis code, evaluated the algorithm, and wrote the original draft of the manuscript.
SLW designed and implemented the OptiFit algorithm and assisted in debugging the analysis code.
MBM and GAD contributed analysis code.
PDS conceived the study, supervised the project, and assisted in debugging the analysis code.
All authors reviewed and edited the manuscript.