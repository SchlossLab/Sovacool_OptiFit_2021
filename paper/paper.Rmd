---
title: "OptiFit: a fast method for fitting amplicon sequences to existing OTUs"
date: '`r Sys.Date()`'
bibliography: references.bib
link-citations: true
output:
  pdf_document:
    includes:
      in_header: preamble.tex
      before_body: head.tex
    fig_caption: yes
csl: msystems.csl
fontsize: 12pt
geometry: margin=1.0in
repository_url: https://github.com/SchlossLab/OptiFitAnalysis
params:
    snakemake: "none"
---

```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE}
schtools::set_knitr_opts()
knitr::opts_chunk$set(fig.path = here::here('figures/'),
                      dpi = 300)
```

```{r deps, message = FALSE}
library(cowplot)
library(glue)
library(here)
library(knitr)
library(schtools)
library(tidyverse)
set.seed(20210624)
snakemake <- params$snakemake
load(here(snakemake@input[['rda']]))
ref_seqs <- read_tsv(here('subworkflows', '0_prep_db', 'data', 
                          'seq_counts.tsv')) %>% 
  pivot_wider(names_from = ref, values_from = nseqs) %>% as.list()

figures_meta <- yaml::read_yaml(here('config', 'figures.yaml'))
figs <- function(fig_name, attribute) {
  value <- figures_meta[[fig_name]][[attribute]]
  if (attribute == 'cap') {
    value <- glue("\\label{fig:[fig_name]}[value]", .open='[', .close = ']')
  } else {
    value <- eval(parse(text = value))
  }
  return(value)
}
```

<!--
- Go back through https://peerj.com/articles/1487/ to get all the arguments for why the qiime based methods are problematicâ€¦
1. The threshold with closed reference is a radius and with de novo its a diameter
2. The gg reference was defined for full length sequences, within a subregion there are duplicate and nearly duplicate sequences
3. Because VSEARCH/USEARCH is a greedy heuristic, its looking for a reference that is close. Although the ordering of the database is not relevant (it was with USEARCH) it gets the wrong number of its (see Figure 5)
-->

## Abstract

Assigning amplicon sequences to operational taxonomic units (OTUs) is often an
important step in characterizing the composition of microbial communities across
large datasets.
OptiClust, a _de novo_ OTU clustering method in the mothur program, has been
shown to produce higher quality OTU assignments than other methods and at
comparable or faster speeds.
A notable difference between _de novo_ clustering and database-dependent methods
is that OTU assignments clustered with _de novo_ methods may change when new
sequences are added to a dataset.
However, in some cases one may wish to incorporate new samples into a previously
clustered dataset without performing clustering again on all sequences, such as
when comparing across datasets or deploying machine learning models where OTUs
are features.
To provide an efficient and robust method to fit amplicon sequence data to
existing OTUs, we developed the OptiFit algorithm.
We tested OptiFit using four microbiome datasets with two different strategies:
by fitting to an external reference database, or by splitting the dataset into a 
reference and query set and fitting the query sequences to the reference set.
The result is a robust implementation of closed and open-reference clustering.
OptiFit produces OTUs of similar quality as OptiClust and at faster speeds when
using the split dataset strategy, although the OTU quality and processing speed
depends on the database chosen when using the external database strategy.
OptiFit provides a suitable option for users who require consistent OTU
assignments at the same quality afforded by _de novo_ clustering methods.

### Importance

**TODO.**
<!--
**"AND, BUT, THEREFORE" structure. start paragraph with question, end with why we should care. transitions to move the story along.**
Advancements in sequencing technology have allowed researchers to affordably generate millions of reads of microorganisms from diverse natural communities,
allowing us to characterize communities.
-->
\newpage

## Introduction

Amplicon sequencing has become a mainstay of microbial ecology.
Researchers can affordably generate millions of sequences to characterize the
composition of hundreds of samples from microbial communities without the need
for culturing.
In many analysis pipelines, 16S rRNA gene sequences are assigned to
operational taxonomic units (OTUs) to facilitate comparison of taxonomic
composition between communities to avoid the need for classification.
A distance threshold of 3% (or sequence similarity of 97%) is commonly used to
cluster sequences into OTUs based on pairwise comparisons of the sequences
within the dataset.
The method chosen for clustering affects the quality of OTU assignments and thus
may impact downstream analyses of community composition
[@westcott_opticlust_2017; @schloss_application_2016;
@westcott_novo_2015].

There are two main categories of OTU clustering algorithms: _de novo_ and
reference-based.
OptiClust is a _de novo_ clustering algorithm which uses the distance score
between all pairs of sequences in the dataset to cluster them into OTUs by
maximizing the Matthews Correlation Coefficient (MCC)
[@westcott_opticlust_2017].
This approach takes into account the distances between all pairs of sequences
when assigning query sequences to OTUs, in contrast to other _de novo_
methods such as the greedy clustering algorithms implemented in USEARCH and
VSEARCH, which only consider the distance between the query sequence and a
representative centroid sequence in the OTU [@edgar_search_2010;
@rognes_vsearch_2016].
A limitation of _de novo_ clustering is that different OTU assignments will be
produced when new sequences are added to a dataset, making it difficult to use
_de novo_ clustering to compare OTUs between different studies.
Additionally, the greedy clustering algorithms are sensitive to the order of the
input sequences: different OTU assignments are produced when the same sequences
are randomly shuffled [@westcott_novo_2015; @he_stability_2015].
Furthermore, since _de novo_ clustering requires calculating and comparing
distances between all sequences in a dataset, the execution time can be slow for
very large datasets.
Reference clustering attempts to overcome the limitations of _de novo_
clustering methods by using a representative set of sequences from a database,
with each reference sequence seeding an OTU.
Commonly, the Greengenes set of representative full length sequences clustered
at 97% similarity is used as the reference with VSEARCH
[@desantis_greengenes_2006; @rognes_vsearch_2016; @noauthor_clustering_nodate].
Query sequences are then assigned to OTUs based on their similarity to the
reference sequences.
Any query sequences that are not within the distance threshold to any of the
reference sequences are either thrown out (closed reference clustering) or
clustered _de novo_ to create additional OTUs (open reference clustering).
While reference-based clustering is generally fast, it is limited by the
diversity of the reference database.
Rare or novel sequences in the sample will be lost in closed reference mode if
they are not represented by a similar sequence in the database.
**TODO: closed uses radius of 3%. de novo uses diameter of 3%. open uses both.**
Previous studies found that the OptiClust _de novo_ clustering algorithm created
the highest quality OTU assignments of all clustering methods [@westcott_opticlust_2017].

To overcome the limitations of current reference-based and _de novo_ clustering
algorithms while maintaining OTU quality, we developed OptiFit, a
reference-based clustering algorithm which uses existing OTUs as the reference
and fits new sequences those reference OTUs.
In contrast to other tools, OptiFit considers all pairwise distance scores
between reference and query sequences when assigning sequences to OTUs in order
to produce OTUs of the highest possible quality.
Here, we tested the OptiFit algorithm with the reference as a database or _de
novo_ OTUs and compared the performance to existing tools.
To evaluate the OptiFit algorithm and compare to existing methods, we used four
published datasets isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples. 
OptiFit is available within the mothur software program.

## Results

### The OptiFit algorithm

OptiFit leverages the method employed by OptiClust of iteratively assigning
sequences to OTUs to produce the highest quality OTUs possible, and extends this
method for reference-based clustering.
OptiClust first seeds each sequence into its own OTU as a singleton. 
Then for each sequence, OptiClust considers whether the sequence should move to
a different OTU or remain in its current OTU, choosing the option that results
in a better Matthews correlation coefficient (MCC).
**TODO: describe how it generates a confusion matrix and calculates the MCC.**
Iterations continue until the MCC stabilizes or until a maximum number of
iterations is reached.
This process produces _de novo_ OTU assignments with the most optimal MCC given
the input sequences.
OptiFit begins where OptiClust ends, starting with a list of reference OTUs and
their sequences, a list of query sequences to assign to the reference OTUs, and
the sequence pairs that are within the distance threshold (e.g. 0.03).
Initially, all query sequences are placed into separate OTUs. 
Then, the algorithm iteratively reassigns the query sequences to the reference 
OTUs to optimize the MCC. 
Alternatively, a sequence will remain unassigned if the MCC value is maximized
when the sequence is a singleton rather than assigned to a reference OTU.
This process is repeated until the MCC changes by no more than 0.0001 (default)
or until a maximum number of iterations is reached (default: 100).
In the closed reference mode, any query sequences that cannot be assigned to
references OTUs are discarded, and the results will only contain OTUs that exist
in the original reference.
In the open reference mode, unassigned query sequences are clustered _de novo_
using OptiClust to generate new OTUs.
The final MCC is reported with the best OTU assignments.
There are two strategies for generating OTUs with OptiFit: 
1) fit the query sequences to reference OTUs generated by _de novo_ clustering an
independent database, or
2) split the dataset into a reference and query fraction, cluster the reference
sequences _de novo_, then fit the query sequences to the reference OTUs.
We clustered sequences from four datasets isolated from soil
[@johnston_metagenomics_2016], marine [@henson_artificial_2016], mouse gut
[@schloss_stabilization_2012], and human gut [@baxter_microbiota-based_2016]
samples to test the performance of OptiFit with both of these strategies.

### Reference clustering with public databases

```{r db_names}
db_names <- names(dn_dbs_mcc)
db_names_upper <- case_when(db_names == 'gg' ~ 'Greengenes', 
                           TRUE ~ toupper(db_names))
```

While _de novo_ clustering produces high quality OTUs, researchers may prefer to
perform reference clustering to a public database because reference-based
methods produce consistent OTUs and are generally faster than _de novo_ methods.
In closed reference mode, sequences that cannot be assigned to reference OTUs
are thrown out, so that the final clustering contains only OTUs that exist in
the reference.
To test how OptiFit performs for this purpose, we fit each dataset to three
databases of reference OTUs: the Greengenes database, the SILVA non-redundant
database, and the Ribosomal Database Project (RDP) [@desantis_greengenes_2006;
@quast_silva_2013; @cole_ribosomal_2014].
Reference OTUs for each database were created by performing _de novo_ clustering
with OptiClust at a distance threshold of 3% (see Figure \ref{fig:workflow}).
The _de novo_ MCC scores were `r dn_dbs_mcc` for `r db_names_upper`,
respectively.
Fitting sequences to Greengenes and SILVA in closed reference mode performed
similarly, with median MCC scores of `r round(closed_fit_gg_mcc, 3)` (**TODO: Pat marked this as 0.80, but the actual number is 0.795414**) and 
`r closed_fit_silva_mcc` respectively, while the median MCC 
was `r closed_fit_rdp_mcc` when fitting to RDP 
(see Figure \ref{fig:results_sum}).
For comparison, clustering datasets with OptiClust produced an average MCC score
of `r opticlust_mcc`.
This gap in OTU quality mostly disappeared when clustering in open reference
mode, which produced median MCCs of `r open_fit_gg_mcc` with Greengenes, 
`r open_fit_silva_mcc` with SILVA, and `r open_fit_rdp_mcc` with the RDP.
Thus, open reference OptiFit produced OTUs of very similar quality as _de novo_
clustering, and closed reference OptiFit followed closely behind as long as a
suitable reference database was chosen.

```{r workflow, fig.dim=figs('workflow','dim'), fig.cap=figs('workflow','cap')}
figs('workflow', 'path') %>% 
  tiff::readTIFF() %>% 
  grid::grid.raster() 
```

Since closed reference clustering does not cluster query sequences that could
not be assigned to reference OTUs, an additional measure of clustering
performance to consider is the fraction of query sequences that were able to be
assigned.
On average, more sequences were assigned with Greengenes as the reference 
(`r frac_fit_gg`%) than with SILVA (`r frac_fit_silva`%) or with the RDP 
(`r frac_fit_rdp`%).
This mirrored the result reported above that Greengenes produced better OTUs in
terms of MCC score than either SILVA or RDP.
Note that _de novo_ and open reference clustering methods always assign 100% of
sequences to OTUs.
The database chosen affects the final OTU assignments considerably in terms of
both MCC score and fraction of query sequences that could be fit to the
reference OTUs.

Despite the drawbacks, closed reference methods have been used when fast
execution speed is required, such as when using very large datasets
[@navas-molina_chapter_2013].
To compare performance in terms of speed, we repeated each OptiFit and OptiClust
run 100 times and measured the execution time.
Across all dataset and database combinations, closed reference OptiFit
outperformed both OptiClust and open reference OptiFit.
For example, with the human dataset fit to SILVA reference OTUs, the average run
times in seconds were `r closed_fit_silva_human_sec` for closed reference
OptiFit, `r opticlust_human_sec` for _de novo_ clustering the dataset, and 
`r open_fit_silva_human_sec` for open reference OptiFit. 
Thus, the OptiFit algorithm continues the precedent that closed reference
clustering sacrifices OTU quality for execution speed.

```{r results_sum, fig.dim=figs('results_sum', 'dim'), fig.cap=figs('results_sum', 'cap')}
figs('results_sum', 'path') %>% 
  tiff::readTIFF() %>% 
  grid::grid.raster() 
```

To compare to the reference clustering methods used by QIIME2, we clustered each
dataset with VSEARCH against the Greengenes database of OTUs previously 
clustered at 97% sequence similarity.
Each reference OTU from the Greengenes 97% database contains one reference
sequence, and VSEARCH maps sequences to the reference based on each individual
query sequence's similarity to the single reference sequence.
In contrast, OptiFit accepts reference OTUs which each may contain multiple
sequences, and the sequence similarity between all query and reference sequences
is considered when assigning sequences to OTUs.
_De novo_ clustering with OptiClust produced `r mcc_opticlust_vs_vsearch`%
higher quality OTUs than VSEARCH in terms of MCC, but performed 
`r sec_opticlust_vs_vsearch`% slower than VSEARCH.
In closed reference mode, OptiFit produced `r mcc_closed_fit_db_vs_vsearch`%
higher quality OTUs than VSEARCH, but VSEARCH was able to map 
`r frac_vsearch_vs_fit`% more query sequences than OptiFit to the Greengenes
reference database.
This is because VSEARCH only considers the distances between each query sequence
to the single reference sequence, while OptiFit considers the distances between
all pairs of sequences in an OTU. <!-- VSEARCH "diameter" vs OptiFit "radius"
-->
When open reference clustering, OptiFit produced higher quality OTUs than
VSEARCH against the Greengenes database, with median MCC scores of 
`r open_fit_gg_mcc` and `r open_vsearch_mcc`, respectively).
In terms of run time, OptiFit outperformed VSEARCH in both closed and open
reference mode by `r sec_closed_fit_db_vs_vsearch`% and 
`r sec_vsearch_vs_open_fit_db`% on average respectively.
Thus, the more stringent OTU definition employed by OptiFit, which requires the
query to be similar to all other sequences in the OTU rather than to one
sequence, resulted in fewer sequences being fit to reference OTUs than when
using VSEARCH, but caused OptiFit to outperform VSEARCH in terms of both OTU
quality and execution time.

### Reference clustering with split datasets

When performing reference clustering against public databases, the database 
chosen greatly affects the quality of OTUs produced.
OTU quality may be poor when the reference database is too unrelated to the
samples of interest, such as when samples contain low abundant or novel
populations.
While _de novo_ clustering overcomes the quality limitations of reference
clustering to databases, OTU assignments are not consistent when new sequences
are added.
Researchers may wish to fit new sequences to existing OTUs when comparing OTUs
across studies or when making predictions with machine learning models.
To determine how well OptiFit performs for fitting new sequences to existing
OTUs, we employed a split dataset strategy, where each dataset was randomly
split into a reference fraction and a query fraction.
Reference sequences were clustered _de novo_ with OptiClust, then query
sequences were fit to the _de novo_ OTUs with OptiFit.

First, we tested whether OptiFit performed as well as _de novo_ clustering when
using the split dataset strategy with half of the sequences selected for
the reference by a simple random sample (a 50% split).
OTU quality was highly similar to that from OptiClust regardless of
mode (`r mcc_opticlust_vs_fit_split_simple`% difference in median MCC).
In closed reference mode, OptiFit was able to fit `r frac_fit_split`% of query
sequences to reference OTUs with the split strategy, a great improvement over
the average `r frac_fit_gg`% of sequences fit to the greengenes database.
In terms of run time, closed and open reference OptiFit performed faster than
OptiClust on whole datasets by `r sec_closed_fit_split_vs_clust`% and 
`r sec_open_fit_split_vs_clust` respectively.
The split dataset strategy also performed `r sec_closed_fit_split_vs_db`% faster
than the database strategy in closed reference mode and 
`r sec_open_fit_split_vs_db`% faster in open reference mode.
Thus, reference clustering with the split dataset strategy creates as high
quality OTUs as _de novo_ clustering yet at a faster run time, and fits far more
query sequences than the database strategy.


```{r results_split, fig.dim=figs('results_split', 'dim'), fig.cap=figs('results_split', 'cap')}
figs('results_split', 'path') %>% 
  tiff::readTIFF() %>% 
  grid::grid.raster() 
```

While we initially tested this strategy using a 50% split of the data into
reference and query fractions, we next investigated whether there was
an optimal reference fraction size.
To test the best reference size, reference sets with 10% to 90% of the
sequences were created, with the remaining sequences used for the query.
OTU quality was remarkably consistent across reference fraction sizes.
For example, splitting the human dataset 100 times yielded a coefficient of
variation of `r cv_fit_split_mcc_human_simple` for the MCC score across all
fractions.
Run time generally decreased as the reference fraction increased; for the human
dataset, the median run time was `r sec_fit_split_human_simple_1` with 10% of
sequences in the reference and `r sec_fit_split_human_simple_9` with 90% of
sequences in the reference (Figure \ref{fig:results_split}).
In closed reference mode, the fraction of sequences that mapped increased as the
reference size increased; for the human dataset, the median fraction mapped was
`r frac_fit_split_human_simple_1` with 10% of sequences in the reference and 
`r frac_fit_split_human_simple_9` with 90% of sequences in the reference. 
These trends held for the other datasets as well (Figure 
\ref{fig:results_split}).
Thus, the reference fraction doid not affect OTU quality in terms of MCC score,
but did affect the run time and the fraction of sequences that mapped during the
closed reference clustering.

After testing the split strategy using a simple random sample to select the
reference sequences, we then investigated other methods of splitting the data.
We tested three methods for selecting the fraction of sequences to be used as
the reference at a size of 50%: a simple random sample, weighting sequences by
relative abundance, and weighting by similarity to other sequences in the
dataset.
OTU quality in terms of MCC was similar with the simple and abundance-weighted
sampling (median MCCs of `r mcc_fit_split_simple` and `r mcc_fit_split_abun`
respectively), but worse for similarity-weighted sampling (median MCC of
`r mcc_fit_split_dist`).
In closed-reference clustering mode, the fraction of sequences that mapped were
similar for simple and abundance-weighted sampling (median fraction mapped of 
`r frac_fit_split_simple` and `r frac_fit_split_abun` respectively), but worse 
for similarity-weighted sampling (median fraction mapped of `r frac_fit_split_dist`).
While simple and abundance-weighted sampling produced better quality OTUs than
similarity-weighted sampling, OptiFit performed faster on
similarity-weighted samples with a median runtime of `r sec_fit_split_dist`
seconds compared to `r sec_fit_split_simple` and `r sec_fit_split_abun` seconds
for simple and abundance-weighted sampling, respectively.
Thus, employing more complicated sampling strategies such as abundance-weighted
and similarity-weighted sampling did not confer any advantages over selecting
the reference via a simple random sample, and in fact decreased OTU quality in
the case of similarity-weighted sampling.

## Discussion

We developed a new algorithm for fitting sequences to existing OTUs and have
demonstrated its suitability for reference-based clustering.
OptiFit makes the iterative method employed by OptiClust available for tasks
where reference-based clustering is required.
We have shown that OTU quality is similar between OptiClust and OptiFit in open
reference mode, regardless of strategy employed.
Open reference OptiFit performs slower than OptiClust due to the additional _de
novo_ clustering step, so users may prefer OptiClust for tasks that do not
require reference OTUs.

When fitting to public databases, OTU quality dropped in closed reference mode
to different degrees depending on the database and dataset source, and no more
than half of query sequences were able to be fit to OTUs across any
dataset/database combination. 
This may reflect limitations of reference
databases, which are unlikely to contain sequences from rare and novel microbes.
This drop in quality was most notable with the RDP reference, which contained only 
`r ref_seqs[['rdp']]` sequences compared to `r ref_seqs[['silva']]` sequences in
SILVA and `r ref_seqs[['gg']]` in Greengenes after trimming to the V4 region.
Note that Greengenes has not been updated since 2013 at the time of this
writing, while SILVA is updated every one to two years with the most recent
release in 2019.
We recommend that users who require an independent reference database opt for
large databases with regular updates and good coverage of microbial diversity.
Since OptiClust still performs faster than open reference OptiFit and creates
higher quality OTUs than closed reference OptiFit with the database strategy, we
recommend using OptiClust rather than fitting to a database whenever consistent
OTUs are not required for the study at hand.

The OptiClust and OptiFit algorithms produced higher quality
OTUs than VSEARCH in open reference, closed reference, or _de novo_ modes.
However, VSEARCH was able to map more sequences to OTUs than OptiFit in closed
reference mode.
While both mothur and VSEARCH use a distance or similarity threshold for
determining how to assign sequences to OTUs, VSEARCH is more permissive than
mothur.
The OptiFit and OptiClust algorithms use all of the sequences to define an
OTU, requiring that all pairs of sequences (including reference and query
sequences) in an OTU are within the distance threshold without penalizing the
MCC.
In contrast, VSEARCH only requires each query sequence to be similar to the
single centroid sequence that seeded the OTU.
Additionally, OTU assignments clustered by VSEARCH are dependent on the order of
the input sequences, because each query is assigned to the OTU of the first
centroid sequence that is found within the distance threshold.
In this way, VSEARCH sacrifices OTU quality in order to allow more sequences to
fit to OTUs.

When fitting with the split dataset strategy, OTU quality was remarkably similar
when reference sequences were selected by a simple random sample or weighted by
abundance, but quality was slightly worse when sequences were weighted by
similarity. 
We recommend using a simple random sample since the more
sophisticated reference selection methods do not offer any benefit. 
The similarity in OTU quality between OptiClust and OptiFit with this strategy
demonstrates the suitability of using OptiFit to fit sequences to existing OTUs,
such as when comparing OTUs across studies.
However, when consistent OTUs are not required, we recommend using OptiClust for
_de novo_ clustering over the split strategy with OptiFit since OptiClust is
simpler to execute but performs similarly in terms of both run time and OTU
quality.

We have developed a new clustering algorithm that allows users to produce high
quality OTUs using already existing OTUs as a reference.
Unlike existing reference-based methods that map query sequences to a single
centroid sequence in each reference OTU, OptiFit considers all sequences in each
reference OTU when fitting query sequences, resulting in OTUs of a similar high
quality as those produced by the _de novo_ OptiClust algorithm.
Potential applications include fitting sequences to reference databases,
comparing taxonomic composition of microbiomes across different studies, 
or using OTU-based machine learning models to make predictions on new data.
OptiFit fills the missing option for fitting query sequences to existing OTUs
that does not sacrifice OTU quality for consistency of OTU assignments.

## Materials and Methods

### Data Processing Steps

We downloaded 16S rRNA gene amplicon sequences from four published datasets
isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples.
These datasets represent a selection of the broad types of natural communities
that microbial ecologists study.
We processed the raw sequences using mothur according to the Schloss Lab MiSeq
SOP as described in the mothur wiki and accompanying study by Kozich _et al._
[@schloss_miseq_nodate; @kozich_development_2013].
These steps included trimming and filtering for quality, aligning to the SILVA
reference alignment [@quast_silva_2013], discarding sequences that aligned
outside the V4 region, removing chimeric reads with UCHIME [@edgar_uchime_2011],
and calculating distances between all pairs of sequences within each dataset
prior to clustering.

### Reference database clustering

To generate reference OTUs from independent databases, we downloaded sequences
from the Greengenes database (v13_8_99) [@desantis_greengenes_2006], SILVA
non-redundant database (v132) [@quast_silva_2013], and the Ribosomal Database
Project (v16) [@cole_ribosomal_2014].
These sequences were processed using the same steps outlined above followed by
clustering sequences into _de novo_ OTUs with OptiClust.
Processed reads from each of the four datasets were clustered with OptiFit to
the reference OTUs generated from each of the three databases.
When reference clustering with VSEARCH, processed datasets were fit directly to
the unprocessed Greengenes 97% OTU reference alignment, since this method is how
VSEARCH is typically used by the QIIME2 software reference-based clustering
[@bolyen_reproducible_2019; @noauthor_clustering_nodate].

### Split dataset clustering

For each dataset, a fraction of the sequences was selected to be clustered _de
novo_ into reference OTUs with OptiClust.
We used three methods for selecting the fraction of sequences to be used
as the reference: a simple random sample, weighting sequences by relative
abundance, and weighting by similarity to other sequences in the dataset.
Dataset splitting was repeated with reference fractions ranging from 10% to 80%
of the dataset and for 100 random seeds.
For each dataset split, the remaining sequences were assigned to the reference
OTUs with OptiFit.

### Benchmarking

Since OptiClust and OptiFit employ a random number generator to break ties
when OTU assignments are of equal quality, they produce slightly different OTU
assignments when repeated with different random seeds.
To capture any variation in OTU quality or execution time, clustering was
repeated with 100 random seeds for each combination of parameters and
input datasets.
We used the benchmark feature provided by Snakemake to measure the run time of
every clustering job.
We calculated the MCC on each set of OTUs to quantify the quality of clustering,
as described by Westcott _et al._ [@westcott_opticlust_2017].

### Data and Code Availability

We implemented the analysis workflow in Snakemake [@koster_snakemake_2012] and
wrote scripts in R [@r_core_team_r_2020], Python [@van_rossum_python_2009], and
GNU bash [@noauthor_bash_nodate].
Software used includes mothur v1.45.0 [@schloss_introducing_2009], VSEARCH
v2.13.3 [@rognes_vsearch_2016], numpy [@harris_array_2020], the tidyverse
metapackage [@wickham_welcome_2019], R Markdown [@xie_r_2018], ggtext
[@wilke_ggtext_2020], the SRA toolkit [@noauthor_sra-tools_nodate], and the
conda environment manager [@noauthor_anaconda_2016].
The complete workflow, manuscript, and conda environment are available at
https://github.com/SchlossLab/Sovacool_OptiFit_2021.
<!-- TODO: update repo link with journal title -->

## Acknowledgements

KLS received support from the NIH Training Program in Bioinformatics (T32 GM070449).
Salary support for PDS came from NIH grants R01CA215574 and U01AI124255.

The funders had no role in study design, data collection and interpretation, 
or the decision to submit the work for publication.

## Author Contributions

KLS wrote the analysis code, evaluated the algorithm, and wrote the original draft of the manuscript.
SLW designed and implemented the OptiFit algorithm and assisted in debugging the analysis code.
MBM and GAD contributed analysis code.
PDS conceived the study, supervised the project, and assisted in debugging the analysis code.
All authors reviewed and edited the manuscript.

## References
