---
title: "OptiFit: a fast method for fitting amplicon sequences to existing OTUs"
date: '`r Sys.Date()`'
authors:
  - name: "Kelly L. Sovacool"
    url: https://github.com/kelly-sovacool
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
    orcid_id: 0000-0003-3283-829X
  - name: "Sarah L. Westcott"
    url: https://github.com/mothur-westcott
    affiliation: Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
  - name: "M. Brodie Mumphrey"
    url: https://github.com/MBMumphrey
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
  - name: "Gabrielle A. Dotson"
    url: https://github.com/dotsonga
    affiliation: Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI
  - name: "Patrick D. Schloss"
    url: https://github.com/pschloss
    affiliation: Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
bibliography: references.bib
output:
  distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
  pdf_document:
    keep_tex: false
    includes:
      in_header: preamble.tex
      before_body: head.tex
      after_body: tail.tex
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs", output_format = "all") })
csl: msystems.csl
fontsize: 12pt
geometry: margin=1.0in
repository_url: https://github.com/SchlossLab/OptiFitAnalysis
creative_commons: CC BY-SA
twitter:
  creator: "@kelly_sovacool"
  site: "@PatSchloss"
---

```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE}
mothuR::set_knitr_opts()
```

## Abstract

Assigning amplicon sequences to Operational Taxonomic Units (OTUs) is an
important step in characterizing the composition of microbial communities across
large datasets. OptiClust, a _de novo_ OTU clustering method in the mothur
program, has been shown to produce higher quality OTU assignments than other
methods and at comparable or faster speeds [@westcott_opticlust_2017;
@schloss_introducing_2009]. A notable difference between _de novo_ clustering
and database-dependent methods is that OTU assignments clustered with _de novo_
methods are not stable when new sequences are added to a dataset
[@westcott_novo_2015]. However, in some cases one may wish to incorporate new
samples into a previously clustered dataset without performing clustering again
on all sequences, such as when deploying a machine learning model where OTUs are
features [@topcuoglu_effective_2019]. To provide an efficient and robust method
to fit amplicon sequence data to existing OTUs, we developed the OptiFit
algorithm as a new component of the mothur program.

- **TODO: summarize results & conclusion**

### Importance

**TODO**

\newpage

## Introduction

Amplicon sequencing has become a mainstay of microbial ecology and
host-associated microbiome research. Researchers can affordably generate
millions of sequences to characterize the composition of hundreds of samples
from culture-independent microbial communities. In a typical analysis pipeline,
16S rRNA gene sequences are assigned to Operational Taxonomic Units (OTUs) to
facilitate comparison of taxonomic composition between communities. A distance
threshold of 3% (or sequence similarity of 97%) is commonly used to cluster
sequences into OTUs based on either a reference database or pairwise comparisons
of the sequences within the dataset. The method chosen for clustering affects
the quality of OTU assignments and thus may impact downstream analyses of
community composition [@westcott_opticlust_2017; @schloss_application_2016;
@westcott_novo_2015].

There are three main categories of OTU clustering algorithms: closed reference,
open reference, and _de novo_ clustering. Closed reference methods assign
sequences to a set of pre-made OTUs generated from reference sequences. If a
query sequence is not within the distance threshold to any of the reference
sequences, it is discarded. While reference-based clustering is generally fast,
it is limited by the diversity represented in the reference database. Rare or
novel sequences in the sample will be lost if they are not represented by a similar sequence in the
database. _De novo_ methods cluster sequences based on their distance to each
other, without the use of an external reference. _De novo_ clustering overcomes
the limitations of reference databases by considering only sequences in the
dataset, but is more computationally intensive and generates different OTU
assignments when new sequences are introduced. Unstable OTU assignments make it
difficult to use _de novo_ clustering to compare taxonomic composition of
communities between studies or to use machine learning models trained with _de
novo_ OTUs to make predictions on new data. Open reference methods take a hybrid
approach, first performing closed reference clustering, then any sequences that
cannot be assigned to reference OTUs are clustered _de novo_ to create
additional OTUs. Previous studies found that the OptiClust _de novo_ clustering
algorithm created the highest quality OTU assignments of all clustering methods
based on the Matthews correlation coefficient (MCC) [@schloss_application_2016;
@westcott_novo_2015].

To overcome the limitations of _de novo_ clustering while maintaining OTU
quality, we developed OptiFit, a reference-based clustering algorithm in the
mothur program which takes existing OTUs as the reference to fit new sequences
to. Here, we tested the OptiFit algorithm with the reference as databases or _de
novo_ OTUs and compared the performance to existing tools.


## Results

### The OptiFit algorithm

- **TODO: ask Sarah Westcott to check the accuracy of this description**

OptiFit leverages the method employed by OptiClust of iteratively assigning
sequences to OTUs to produce the highest quality OTUs possible, and extends this
method for reference-based clustering. OptiFit takes as input a list of
reference OTUs and their sequences, a list of query sequences to assign to the
reference OTUs, the sequence pairs that are within the distance threshold (e.g.
0.03), and the metric to assess clustering quality (default: MCC). Query
sequences are randomly seeded in reference OTUs, then for each sequence the
algorithm calculates the quality metric based on whether the sequences stays in
its current OTU or moves to each of the other OTUs. This process is repeated
until the quality metric stabilizes, changing by no more than 0.0001 by default,
or until a maximum number of iterations is reached (default: 100). In
closed-reference mode, any query sequences that cannot be assigned are thrown
out (**TODO: what determines whether a seq can't be assigned?**), and the
results only contain OTUs that exist in the original reference. In
open-reference mode, un-assigned query sequences are clustered _de novo_ using
OptiClust to generate additional OTUs. The final quality score is reported with
the best OTU assignments.

To evaluate the OptiFit algorithm and compare to existing methods, we used four
published datasets isolated from soil [@johnston_metagenomics_2016], marine
[@henson_artificial_2016], mouse gut [@schloss_stabilization_2012], and human
gut [@baxter_microbiota-based_2016] samples. There are two strategies for
generating OTUs with OptiFit: 1) fit sequences to reference OTUs of an
independent database, or 2) split the dataset into a reference and query
fraction, then fit the query sequences to OTUs generated by clustering the
reference sequences _de novo_. For each dataset repeated with 100 random seeds,
we generated OTUs with OptiFit using both strategies, and also clustered _de
novo_ OTUs with OptiClust for comparison. All clustering was performed at a
sequence distance threshold of 0.03 and OTU quality was evaluated using the
Matthews Correlation Coefficient (MCC) as described previously
[@schloss_application_2016; @westcott_novo_2015]. We calculated the fraction of
query sequences that were fit to existing OTUs in closed reference mode as an
additional measure of quality for this mode.

### Reference clustering with public databases

- **TODO:** separate paragraphs for closed & open reference clustering. weave in vsearch within those paragraphs. mention median MCC values.
- **TODO:** avoid slightly/much -- use numbers, e.g. X% better/worse.
- **TODO:** put the comparison at the beginning of the sentence, so you don't have to know what it is at the end.

To evaluate reference-based clustering with independent databases, we fit each
dataset to reference OTUs generated by _de novo_ clustering the Greengenes
database (v13_8_99), Silva non-redundant database (v132), and the Ribosomal
Database Project (RDP; v16). In open reference mode, OTU quality was similar
between fitting the datasets to reference OTUs with OptiFit and clustering the
datasets _de novo_ with OptiClust. This held true for all datasets and reference
databases. However, in closed reference mode, OTU quality was slightly worse
when fitting to Greengenes and Silva, and much worse when fitting to RDP as
compared to OptiClust. No more than half of query sequences were fit to
reference OTUs in closed reference mode across any dataset/database combination.
**TODO: specify exact numbers for fraction mapped.**
OptiFit was able to fit **X** more query sequences to reference OTUs created with the
Greengenes and Silva databases than with RDP. In terms of run time,
closed reference OptiFit outperformed OptiClust, while OptiClust outperformed
open reference OptiFit.

To compare to existing software, vsearch was used to cluster OTUs _de novo_ or
with reference-based clustering to the greengenes database. For all datasets and
clustering methods (_de novo_, open reference, and closed reference), mothur's
clustering algorithms produced higher quality OTUs than vsearch. When
closed reference clustering against the greengenes database, vsearch was able to
map more query sequences to the reference than mothur's OptiFit algorithm. In
terms of runtime, OptiFit generally performed faster than vsearch when reference
clustering, while vsearch _de novo_ clustering outperformed OptiClust.
  
### Reference clustering with split datasets

Datasets were randomly split into a reference fraction and a query fraction.
Reference sizes from 10% to 80% of the sequences were created, with the
remaining sequences used for the query. Reference sequences were clustered _de
novo_ with OptiClust, then query sequences were fit to the _de novo_ OTUs with
OptiFit.

OTU quality from the split dataset strategy with OptiFit was highly similar to
that from _de novo_ clustering the whole dataset with OptiClust regardless of
mode. OTU quality was remarkably stable across 100 different random seeds. In
terms of runtime, closed reference OptiFit performed faster than OptiClust on
whole datasets. In open reference mode, OptiClust performed faster than OptiFit
only when the OptiFit reference fraction was 30% or less. The split dataset
strategy performed just as well as the database strategy in open reference mode
regardless of database used, and outperformed the database strategy in
closed reference mode.

We also tested three methods for selecting the sequences to be used as the
reference; a simple random sample, weighting sequences by relative abundance,
and weighting by similarity to other sequences in the dataset. OTU quality was
similar with the simple and abundance-weighted sampling, but slightly worse with
similarity-weighted sampling. In closed reference mode, The fraction of query
sequences that can be fit to the reference OTUs decreases as the reference
fraction increases.

## Discussion

- **TODO:** for these data, we don't see a compelling reason to use reference-based clustering over _de novo_. it was supposed to speed things up. the reason to do reference-based is if you like the ref OTUs -- e.g. for ML or downstream tools e.g. PiCrust?
- **TODO:** highlight difference between what we're doing and what previously was done.
  others use single ref seq to define an OTU, while we use all the ref & query seqs to define an otu. highlight why ours is better than previous methods.

We developed a new algorithm for fitting sequences to existing OTUs and have
demonstrated its suitability for reference-based clustering. OptiFit makes the
iterative method employed by OptiClust available for tasks where
reference-based clustering is required. We have shown that OTU quality is
similar between OptiClust and OptiFit in open reference mode, regardless of
strategy employed. open reference OptiFit does perform slower than OptiClust
due to the additional _de novo_ clustering step, so users may prefer OptiClust
for tasks that do not require reference OTUs.

When fitting to public databases, OTU quality dropped in closed reference mode
to different degrees depending on the database and dataset source, and no more
than half of query sequences were able to be fit to OTUs across any
dataset/database combination. This may reflect limitations of reference
databases, which are unlikely to contain sequences from rare and novel microbes.
This drop in quality was most notable with RDP. We recommend users who require
an independent reference database opt for Greengenes or Silva instead. Since
OptiClust performs faster than open reference OptiFit and creates higher quality
OTUs than closed reference OptiFit with the database strategy, we recommend
using OptiClust rather than fitting to a database where possible.
(**TODO: "if you don't have breadth, closed ref will suck." - Pat**)

The mothur algorithms produced higher quality OTUs than vsearch in
open reference, closed reference, or _de novo_ modes. However, vsearch was able
to fit more sequence into OTUs than OptiFit in closed reference mode. While both
mothur and vsearch use a dissimilarity threshold for determining how to assign
sequences into OTUs, vsearch is more permissive than mothur. Mothur requires
that all pairs of sequences in an OTU are within the dissimilarity threshold
without penalizing the MCC, while vsearch only requires sequences to be similar
to one other sequence in the OTU. In this way, vsearch sacrifices OTU quality in
order to allow more sequences to fit to OTUs. Users who require closed reference
clustering may prefer to use vsearch if they wish to maximize the fraction of
sequences that can be fit at the cost of OTU quality. However, mothur's
OptiClust or OptiFit are preferred for _de novo_ or open reference clustering.

When fitting with the split dataset strategy, OTU quality was remarkably similar
when reference sequences were selected by a simple random sample or weighted by
abundance, but quality was slightly worse when sequences were weighted by
similarity. We recommend using a simple random sample since the more
sophisticated reference selection methods do not offer any benefit. The
similarity in OTU quality between OptiClust and OptiFit with this strategy
demonstrates the suitability of using OptiFit to fit sequences to existing OTUs,
such as when using already-trained machine learning models to make predictions
on new data.

- **TODO: big picture concluding paragraph**

## Materials and Methods

### Data Processing Steps 

### Benchmarking

### Data and Code Availability

We implemented the analysis workflow in Snakemake [@koster_snakemake_2012] and
relied on Python [@van_rossum_python_2009], R [@r_core_team_r_2020], and GNU
bash. Software used includes mothur v1.45.0 [@schloss_introducing_2009], vsearch
v2.13.3 [@rognes_vsearch_2016], numpy [@harris_array_2020], the Tidyverse
metapackage [@wickham_welcome_2019], R Markdown [@xie_r_2018], and the conda
environment manager [@noauthor_anaconda_2016]. The complete workflow,
manuscript, and conda environment are available at **TODO: UPDATED REPO LINK**.

## Acknowledgements {.appendix}

KLS received support from the NIH Training Program in Bioinformatics (T32 GM070449).

PDS received support from **TODO: Pat's grant(s)**.

The funders had no role in study design, data collection and interpretation, 
or the decision to submit the work for publication.

## Author Contributions {.appendix}

KLS wrote the analysis code, evaluated the algorithm, and wrote the original draft of the manuscript.
SLW designed and implemented the OptiFit algorithm and assisted in debugging the analysis code.
MBM and GAD contributed analysis code.
PDS conceived the study, supervised the project, and assisted in debugging the analysis code.
All authors reviewed and edited the manuscript.